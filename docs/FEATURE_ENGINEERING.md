# Feature Engineering for Risk Management

This document outlines the feature types supported and planned for Corint's risk management platform.

## ğŸš¦ Implementation Status Overview

| Feature Category | Status | Production Ready | In Development |
|-----------------|--------|------------------|----------------|
| **Aggregation** | ğŸŸ¢ **Implemented** | count, sum, avg, min, max, distinct | stddev, percentile, median, mode, entropy |
| **State** | ğŸ”´ **Planned** | - | All methods (z_score, outlier detection, etc.) |
| **Sequence** | ğŸ”´ **Planned** | - | All methods (pattern matching, trends, etc.) |
| **Graph** | ğŸ”´ **Planned** | - | All methods (network analysis, centrality, etc.) |
| **Expression** | ğŸŸ¢ **Implemented** | expression | ML model integration (planned) |
| **Lookup** | ğŸŸ¢ **Implemented** | lookup | - |

**Legend:**
- ğŸŸ¢ **Implemented**: Ready for production use
- ğŸŸ¡ **Partial**: Some methods implemented
- ğŸ”´ **Planned**: Documented but not yet implemented

> âš ï¸ **Important**: Sections marked as "Planned" show the intended design and API. The implementation is in development and not yet available in production.

---

## Overview

Feature engineering in risk management follows a structured approach based on **what you want to measure**:

1. **Aggregation (æ•°ä¸œè¥¿)** ğŸŸ¢ - Counting and aggregating events/values
2. **State (çœ‹æœ€è¿‘çŠ¶æ€)** ğŸ”´ - Checking current state and statistical comparisons
3. **Sequence (çœ‹è¿‡ç¨‹)** ğŸ”´ - Analyzing patterns and trends over time
4. **Graph (çœ‹å…³ç³»å›¾)** ğŸ”´ - Analyzing connections and networks between entities
5. **Expression (ç®—åˆ†æ•°)** ğŸŸ¢ - Computing scores and evaluations
6. **Lookup (æŸ¥é¢„ç®—å€¼)** ğŸŸ¢ - Retrieving pre-computed feature values

> **Note:** List/Set operations (blacklist/whitelist checking, etc.) are implemented separately in Corint's list management system and are not covered in this feature engineering document.

---

## Methods by Category

### 1. Aggregation Methods ğŸŸ¢ Implemented
> **Rust Implementation:** `AggregationExecutor::execute(method: AggregationType, config: AggregationConfig)`
>
> **Design Pattern:** Unified executor with method-based dispatch
>
> **Status:** âœ… Core methods production-ready | ğŸ“‹ Advanced statistics in development

**âœ… Implemented (Production-Ready):**
- `count` - Count events matching conditions within time window
  - *Example: ç”¨æˆ·è¿‡å»24å°æ—¶ç™»å½•äº†5æ¬¡*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - æš´åŠ›ç ´è§£æ£€æµ‹ï¼šç»Ÿè®¡1å°æ—¶å†…å¤±è´¥ç™»å½•æ¬¡æ•°ï¼Œè¶…è¿‡10æ¬¡è§¦å‘è´¦æˆ·é”å®š
    - äº¤æ˜“é¢‘ç‡ç›‘æ§ï¼šç»Ÿè®¡ç”¨æˆ·24å°æ—¶å†…äº¤æ˜“æ¬¡æ•°ï¼Œå¼‚å¸¸é«˜é¢‘å¯èƒ½æ˜¯ç›—å·
    - APIé™æµï¼šç»Ÿè®¡IPåœ°å€1åˆ†é’Ÿå†…è¯·æ±‚æ¬¡æ•°ï¼Œè¶…è¿‡100æ¬¡æ‹’ç»æœåŠ¡
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: cnt_userid_login_1h_failed
      type: aggregation
      method: count
      datasource: postgresql_events
      entity: events
      dimension: user_id              # æŒ‰ç”¨æˆ·åˆ†ç»„ (GROUP BY user_id)
      dimension_value: "{event.user_id}"
      window: 1h
      # æ³¨æ„ï¼šcountæ“ä½œä¸éœ€è¦fieldå­—æ®µï¼Œåªè®¡ç®—ç¬¦åˆæ¡ä»¶çš„äº‹ä»¶æ•°é‡
      when:
        all:
          - type == "login"               # Database field (no prefix)
          - status == "failed"             # Database field (no prefix)
    ```

- `sum` - Sum numeric field values
  - *Example: ç”¨æˆ·è¿‡å»30å¤©äº¤æ˜“æ€»é¢ä¸º Â¥15,000*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - æ´—é’±æ£€æµ‹ï¼šç»Ÿè®¡è´¦æˆ·24å°æ—¶å†…è½¬è´¦æ€»é‡‘é¢ï¼Œè¶…è¿‡Â¥50ä¸‡éœ€äººå·¥å®¡æ ¸
    - ä¿¡ç”¨é¢åº¦ç®¡ç†ï¼šç»Ÿè®¡ç”¨æˆ·30å¤©æ¶ˆè´¹æ€»é¢ï¼Œåˆ¤æ–­æ˜¯å¦è¶…è¿‡ä¿¡ç”¨é¢åº¦
    - ç§¯åˆ†æ¬ºè¯ˆï¼šç»Ÿè®¡ç”¨æˆ·1å°æ—¶å†…è·å–ç§¯åˆ†æ€»æ•°ï¼Œå¼‚å¸¸é«˜é¢å¯èƒ½æ˜¯åˆ·ç§¯åˆ†
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: sum_userid_txn_amt_24h
      type: aggregation
      method: sum
      datasource: postgresql_events
      entity: events
      dimension: user_id              # æŒ‰ç”¨æˆ·åˆ†ç»„ (GROUP BY user_id)
      dimension_value: "{event.user_id}"
      field: amount                   # è®¡ç®—é‡‘é¢çš„æ€»å’Œ (SUM(amount))
      window: 24h
      when: type == "transaction"         # Database field (no prefix)
    ```

- `avg` - Average of field values
  - *Example: ç”¨æˆ·è¿‡å»7å¤©å¹³å‡æ¯ç¬”äº¤æ˜“é‡‘é¢ Â¥500*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - å¼‚å¸¸äº¤æ˜“é‡‘é¢æ£€æµ‹ï¼šç”¨æˆ·å¹³å‡äº¤æ˜“Â¥500ï¼Œçªç„¶å‡ºç°Â¥50,000äº¤æ˜“éœ€éªŒè¯
    - ç”¨æˆ·ç”»åƒï¼šè®¡ç®—ç”¨æˆ·å¹³å‡è®¢å•é‡‘é¢ï¼Œç”¨äºç”¨æˆ·åˆ†å±‚ï¼ˆé«˜/ä¸­/ä½æ¶ˆè´¹ï¼‰
    - ä¼šè¯æ—¶é•¿åˆ†æï¼šç»Ÿè®¡ç”¨æˆ·å¹³å‡ä¼šè¯æ—¶é•¿ï¼Œå¼‚å¸¸çŸ­å¯èƒ½æ˜¯æœºå™¨äºº
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: avg_userid_order_amt_30d
      type: aggregation
      method: avg
      datasource: postgresql_events
      entity: events
      dimension: user_id              # æŒ‰ç”¨æˆ·åˆ†ç»„ (GROUP BY user_id)
      dimension_value: "{event.user_id}"
      field: amount                   # è®¡ç®—é‡‘é¢çš„å¹³å‡å€¼ (AVG(amount))
      window: 30d
      when: type == "order"               # Database field (no prefix)
    ```

- `max` - Maximum value
  - *Example: ç”¨æˆ·è¿‡å»24å°æ—¶å•ç¬”æœ€å¤§äº¤æ˜“ Â¥2,000*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - å¤§é¢äº¤æ˜“ç›‘æ§ï¼šæ£€æµ‹ç”¨æˆ·å†å²æœ€å¤§äº¤æ˜“é‡‘é¢ï¼Œå½“å‰äº¤æ˜“è¶…è¿‡3å€éœ€éªŒè¯
    - å•ç¬”é™é¢æ£€æŸ¥ï¼šæ–°æ³¨å†Œç”¨æˆ·24å°æ—¶å†…æœ€å¤§äº¤æ˜“ä¸è¶…è¿‡Â¥5,000
    - å¼‚å¸¸è¡Œä¸ºè¯†åˆ«ï¼šIPåœ°å€å…³è”çš„æœ€å¤§ç”¨æˆ·æ•°è¶…è¿‡50ï¼Œå¯èƒ½æ˜¯ä»£ç†æˆ–å…¬å…±WiFi
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: max_userid_txn_amt_90d
      type: aggregation
      method: max
      datasource: postgresql_events
      entity: events
      dimension: user_id              # æŒ‰ç”¨æˆ·åˆ†ç»„ (GROUP BY user_id)
      dimension_value: "{event.user_id}"
      field: amount                   # è®¡ç®—é‡‘é¢çš„æœ€å¤§å€¼ (MAX(amount))
      window: 90d
      when: type == "transaction"         # Database field (no prefix)
    ```

- `min` - Minimum value
  - *Example: ç”¨æˆ·è¿‡å»7å¤©å•ç¬”æœ€å°äº¤æ˜“ Â¥10*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - æµ‹è¯•äº¤æ˜“æ£€æµ‹ï¼šå¤§é‡Â¥0.01å°é¢äº¤æ˜“å¯èƒ½æ˜¯ç›—å¡æµ‹è¯•
    - åˆ·å•è¯†åˆ«ï¼šæœ€å°è®¢å•é‡‘é¢å¼‚å¸¸ä½ï¼ˆå¦‚Â¥0.1ï¼‰é…åˆé«˜é¢‘æ¬¡ï¼Œç–‘ä¼¼åˆ·å•
    - å¼‚å¸¸æŠ˜æ‰£ç›‘æ§ï¼šè®¢å•æœ€å°é‡‘é¢ä¸ºÂ¥1ï¼Œå¯èƒ½å­˜åœ¨ä¼˜æƒ åˆ¸æ¼æ´
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: min_userid_order_amt_7d
      type: aggregation
      method: min
      datasource: postgresql_events
      entity: events
      dimension: user_id              # æŒ‰ç”¨æˆ·åˆ†ç»„ (GROUP BY user_id)
      dimension_value: "{event.user_id}"
      field: amount                   # è®¡ç®—é‡‘é¢çš„æœ€å°å€¼ (MIN(amount))
      window: 7d
      when: type == "order"               # Database field (no prefix)
    ```

- `distinct` - Count unique values
  - *Example: ç”¨æˆ·è¿‡å»7å¤©ä½¿ç”¨äº†3ä¸ªä¸åŒè®¾å¤‡*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - è´¦å·å…±äº«æ£€æµ‹ï¼šç”¨æˆ·24å°æ—¶å†…ä½¿ç”¨è¶…è¿‡5ä¸ªä¸åŒè®¾å¤‡ï¼Œå¯èƒ½æ˜¯è´¦å·è¢«ç›—æˆ–å…±äº«
    - IPè·³è·ƒæ£€æµ‹ï¼šç”¨æˆ·1å°æ—¶å†…ä½¿ç”¨è¶…è¿‡10ä¸ªä¸åŒIPï¼Œå¯èƒ½ä½¿ç”¨ä»£ç†æ± 
    - å¤šè´¦æˆ·å…³è”ï¼šåŒä¸€è®¾å¤‡24å°æ—¶å†…ç™»å½•è¶…è¿‡20ä¸ªä¸åŒè´¦æˆ·ï¼Œå¯èƒ½æ˜¯æ‰¹é‡æ“ä½œ
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: distinct_userid_device_24h
      type: aggregation
      method: distinct
      datasource: postgresql_events
      entity: events
      dimension: user_id              # æŒ‰ç”¨æˆ·åˆ†ç»„ (GROUP BY user_id)
      dimension_value: "{event.user_id}"
      field: device_id                # ç»Ÿè®¡ä¸åŒè®¾å¤‡IDçš„æ•°é‡ (COUNT(DISTINCT device_id))
      window: 24h
    ```

**Planned:**
- `stddev` - Standard deviation
  - *Example: ç”¨æˆ·äº¤æ˜“é‡‘é¢æ ‡å‡†å·® Â¥350ï¼Œæ³¢åŠ¨è¾ƒå¤§*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - è¡Œä¸ºç¨³å®šæ€§åˆ†æï¼šäº¤æ˜“é‡‘é¢æ ‡å‡†å·®è¿‡å¤§ï¼Œè¡Œä¸ºä¸ç¨³å®šï¼Œå¯èƒ½è¢«ç›—å·
    - å¼‚å¸¸æ³¢åŠ¨æ£€æµ‹ï¼šç”¨æˆ·å†å²æ ‡å‡†å·®Â¥50ï¼Œè¿‘æœŸæ ‡å‡†å·®Â¥500ï¼Œè¡Œä¸ºå‰§å˜
    - ç”¨æˆ·åˆ†ç¾¤ï¼šä½æ ‡å‡†å·®ç”¨æˆ·ï¼ˆå›ºå®šæ¶ˆè´¹ï¼‰vs é«˜æ ‡å‡†å·®ç”¨æˆ·ï¼ˆæ¶ˆè´¹éšæœºï¼‰
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: stddev_userid_txn_amt_30d
      type: aggregation
      method: stddev
      datasource: postgresql_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: amount
      window: 30d
      when: type == "transaction"         # Database field (no prefix)
    ```

- `variance` - Variance
  - *Example: ç”¨æˆ·äº¤æ˜“é‡‘é¢æ–¹å·® 122,500*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - é£é™©è¯„åˆ†ï¼šé«˜æ–¹å·®ç”¨æˆ·é£é™©æ›´é«˜ï¼Œè¡Œä¸ºä¸å¯é¢„æµ‹
    - æœºå™¨äººæ£€æµ‹ï¼šæœºå™¨äººäº¤æ˜“æ–¹å·®é€šå¸¸å¾ˆå°ï¼ˆå›ºå®šé‡‘é¢ï¼‰
    - ä¿¡ç”¨è¯„ä¼°ï¼šä½æ–¹å·®ç”¨æˆ·è¿˜æ¬¾è¡Œä¸ºæ›´ç¨³å®šï¼Œä¿¡ç”¨æ›´å¥½
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: variance_userid_txn_amt_30d
      type: aggregation
      method: variance
      datasource: postgresql_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: amount
      window: 30d
      when: type == "transaction"         # Database field (no prefix)
    ```

- `percentile` - Nth percentile value
  - *Example: ç”¨æˆ·äº¤æ˜“é‡‘é¢P95ä¸º Â¥1,800*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - å¼‚å¸¸é˜ˆå€¼è®¾å®šï¼šè¶…è¿‡P95çš„äº¤æ˜“éœ€è¦é¢å¤–éªŒè¯
    - åŠ¨æ€é™é¢ï¼šæ ¹æ®ç”¨æˆ·P90äº¤æ˜“é‡‘é¢è®¾ç½®æ¯æ—¥é™é¢
    - ä¿¡ç”¨é¢åº¦ï¼šç”¨æˆ·P75æ¶ˆè´¹é‡‘é¢ä½œä¸ºä¿¡ç”¨é¢åº¦å‚è€ƒ
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: p95_userid_txn_amt_30d
      type: aggregation
      method: percentile
      datasource: postgresql_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: amount
      percentile: 95
      window: 30d
      when: type == "transaction"         # Database field (no prefix)
    ```

- `median` - Median value (50th percentile)
  - *Example: ç”¨æˆ·äº¤æ˜“é‡‘é¢ä¸­ä½æ•° Â¥450*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - æŠ—å¼‚å¸¸å€¼ç»Ÿè®¡ï¼šä¸­ä½æ•°ä¸å—æç«¯å€¼å½±å“ï¼Œæ›´å‡†ç¡®åæ˜ ç”¨æˆ·å…¸å‹è¡Œä¸º
    - ç”¨æˆ·ç”»åƒï¼šä¸­ä½æ•°è®¢å•é‡‘é¢ç”¨äºç”¨æˆ·ä»·å€¼è¯„ä¼°
    - å¼‚å¸¸æ£€æµ‹ï¼šå½“å‰äº¤æ˜“æ˜¯ä¸­ä½æ•°çš„10å€ï¼Œéœ€è¦éªŒè¯
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: median_userid_txn_amt_30d
      type: aggregation
      method: median
      datasource: postgresql_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: amount
      window: 30d
      when: type == "transaction"         # Database field (no prefix)
    ```

- `mode` - Most frequent value
  - *Example: ç”¨æˆ·æœ€å¸¸è§çš„äº¤æ˜“é‡‘é¢ Â¥100*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - å……å€¼æ¨¡å¼è¯†åˆ«ï¼šç”¨æˆ·æœ€å¸¸å……å€¼Â¥100ï¼Œå¼‚å¸¸å……å€¼Â¥10,000éœ€éªŒè¯
    - åˆ·å•æ£€æµ‹ï¼šå¤§é‡ç›¸åŒé‡‘é¢è®¢å•ï¼ˆä¼—æ•°å æ¯”>80%ï¼‰ç–‘ä¼¼åˆ·å•
    - ä¹ æƒ¯è¯†åˆ«ï¼šç”¨æˆ·æœ€å¸¸åœ¨æ™šä¸Š8ç‚¹ç™»å½•ï¼Œå‡Œæ™¨3ç‚¹ç™»å½•å¼‚å¸¸
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: mode_userid_txn_amt_30d
      type: aggregation
      method: mode
      datasource: postgresql_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: amount
      window: 30d
      when: type == "transaction"         # Database field (no prefix)
    ```

- `entropy` - Shannon entropy (diversity measure)
  - *Example: ç”¨æˆ·äº¤æ˜“ç±»å‹ç†µå€¼2.3ï¼Œè¡Œä¸ºå¤šæ ·åŒ–*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - æœºå™¨äººæ£€æµ‹ï¼šç†µå€¼è¿‡ä½ï¼ˆ<0.5ï¼‰ï¼Œè¡Œä¸ºæ¨¡å¼å•ä¸€ï¼Œå¯èƒ½æ˜¯æœºå™¨äºº
    - è´¦å·æ´»è·ƒåº¦ï¼šç†µå€¼é«˜çš„ç”¨æˆ·è¡Œä¸ºä¸°å¯Œï¼Œæ›´åƒçœŸå®ç”¨æˆ·
    - å¼‚å¸¸æ£€æµ‹ï¼šç”¨æˆ·å†å²ç†µå€¼2.5ï¼Œè¿‘æœŸé™è‡³0.3ï¼Œè¡Œä¸ºå¼‚å¸¸å•ä¸€
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: entropy_userid_txn_type_30d
      type: aggregation
      method: entropy
      datasource: postgresql_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: transaction_type
      window: 30d
      when: type == "transaction"         # Database field (no prefix)
    ```

> **Note:** Ratio- and rate-type metrics (e.g. success rate, failure rate, conversion rate) are **not** Aggregation operators. They are derived from aggregation results and must be implemented via **Expression operators**.

**Principle:** Aggregation = Single data source + Single window + Single grouping + One-pass scan

```rust
enum AggregationType {
    Count, Sum, Avg, Max, Min, Distinct,
    StdDev, Variance, Percentile(u8), Median, Mode, Entropy,
}

struct AggregationConfig {
    pub datasource: String,
    pub entity: String,
    pub dimension: String,
    pub dimension_value: String,
    pub field: Option<String>,       // countä¸éœ€è¦ï¼Œå…¶ä»–éœ€è¦
    pub window: Duration,
    pub when: Option<Condition>,
}

// âœ… æ‰€æœ‰Aggregationæ“ä½œç¬¦å¯ä»¥ç”¨ç»Ÿä¸€çš„å‡½æ•°å®ç°ï¼
// å…±åŒé€»è¾‘:
// - Time window filtering (windowå­—æ®µ)
// - Dimension grouping (dimension, dimension_value)
// - Condition matching (whenå­—æ®µ)
// - One-pass aggregation (ä¸åŒçš„operator)
impl AggregationExecutor {
    fn execute(&self, op: AggregationType, config: &AggregationConfig) -> Result<Value> {
        // 1. æ„å»ºæŸ¥è¯¢
        let sql = self.build_query(op, config)?;

        // æ ¹æ®operatorç”Ÿæˆä¸åŒçš„SQLèšåˆå‡½æ•°:
        // COUNT(*), SUM(field), AVG(field), MAX(field), MIN(field),
        // COUNT(DISTINCT field), STDDEV(field), etc.

        // 2. æ‰§è¡ŒæŸ¥è¯¢
        self.datasource.query(&sql)
    }

    fn build_query(&self, op: AggregationType, config: &AggregationConfig) -> String {
        let agg_expr = match op {
            AggregationType::Count => "COUNT(*)".to_string(),
            AggregationType::Sum => format!("SUM({})", config.field.as_ref().unwrap()),
            AggregationType::Avg => format!("AVG({})", config.field.as_ref().unwrap()),
            AggregationType::Max => format!("MAX({})", config.field.as_ref().unwrap()),
            AggregationType::Min => format!("MIN({})", config.field.as_ref().unwrap()),
            AggregationType::Distinct => format!("COUNT(DISTINCT {})", config.field.as_ref().unwrap()),
            AggregationType::StdDev => format!("STDDEV({})", config.field.as_ref().unwrap()),
            // ... other operators
        };

        format!(
            "SELECT {} FROM {} WHERE {} = {} AND timestamp > now() - {} {}",
            agg_expr,
            config.entity,
            config.dimension,
            config.dimension_value,
            config.window,
            config.when.as_ref().map(|w| format!("AND {}", w)).unwrap_or_default()
        )
    }
}
```

---

## æ‰€æœ‰Featureç±»å‹çš„DSLä¸€è‡´æ€§åˆ†æ

### è·¨ç±»å‹å­—æ®µå¯¹æ¯”è¡¨

| å­—æ®µ | Aggregation | State | Sequence | Graph | Expression | Lookup | è¯´æ˜ |
|------|-------------|-------|----------|-------|------------|--------|------|
| `type` | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | æ‰€æœ‰ç±»å‹éƒ½éœ€è¦ |
| `method` | âœ… | âœ… | âœ… | âœ… | âœ… | âŒ | Lookupä¸éœ€è¦ |
| `datasource` | âœ… | âœ… | âœ… | âœ… | âŒ | âœ… | Expressionä¸éœ€è¦ |
| `entity` | âœ… | âœ… | âœ… | âš ï¸ | âŒ | âŒ | æŒ‡å®šè¡¨å/æ•°æ®å®ä½“ï¼ˆè§ä¸‹æ–¹è¯´æ˜ï¼‰ |
| `dimension` | âœ… | âœ… | âœ… | âœ… | âŒ | âŒ | åˆ†ç»„ç»´åº¦ |
| `dimension_value` | âœ… | âœ… | âœ… | âœ… | âŒ | âŒ | ç»´åº¦å€¼ |
| `dimension_value2` | âŒ | âŒ | âŒ | âš ï¸ | âŒ | âŒ | ç¬¬äºŒä¸ªç»´åº¦å€¼ï¼ˆä»…åŒèŠ‚ç‚¹Graphæ–¹æ³•ï¼‰ |
| `dimension2` | âŒ | âŒ | âŒ | âœ… | âŒ | âŒ | ç¬¬äºŒç»´åº¦ï¼ˆGraphå…³è”ç»´åº¦ï¼‰ |
| `window` | âœ… | âœ… | âœ… | âœ… | âŒ | âŒ | æ—¶é—´çª—å£ |
| `when` | âœ… | âœ… | âœ… | âŒ | âŒ | âŒ | æ¡ä»¶è¿‡æ»¤ |
| `field` | âš ï¸ | âœ… | âš ï¸ | âŒ | âŒ | âŒ | è®¡ç®—å­—æ®µ |

### `entity` å­—æ®µè¯´æ˜

**`entity` çš„ä½œç”¨ï¼šæŒ‡å®šä»å“ªä¸ªè¡¨/æ•°æ®å®ä½“ä¸­è¯»å–æ•°æ®**

| Datasourceç±»å‹ | éœ€è¦entity? | entityçš„å«ä¹‰ | ç¤ºä¾‹ |
|---------------|-----------|------------|------|
| **PostgreSQL** | âœ… éœ€è¦ | è¡¨å | `entity: events` â†’ æŸ¥è¯¢ `events` è¡¨ |
| **ClickHouse** | âœ… éœ€è¦ | è¡¨å | `entity: events` â†’ æŸ¥è¯¢ `events` è¡¨ |
| **Neo4j** | âš ï¸ å–å†³äºè®¾è®¡ | èŠ‚ç‚¹æ ‡ç­¾æˆ–å…³ç³»ç±»å‹ | `entity: events` æˆ–ä¸éœ€è¦ |
| **Redis** | âŒ ä¸éœ€è¦ | N/A (key-valueå­˜å‚¨) | ç›´æ¥é€šè¿‡keyè®¿é—® |
| **Expression** | âŒ ä¸éœ€è¦ | N/A (ä¸è®¿é—®æ•°æ®æº) | åªä½¿ç”¨å…¶ä»–ç‰¹å¾çš„ç»“æœ |

**SQLç”Ÿæˆç¤ºä¾‹ï¼š**

```yaml
# PostgreSQL/ClickHouse
- name: cnt_userid_login_24h
  datasource: postgresql_events
  entity: events              # â† æŒ‡å®šè¡¨å
  dimension: user_id
  window: 24h
```

ç”Ÿæˆçš„SQLï¼š
```sql
SELECT COUNT(*)
FROM events                   -- â† entity æ˜ å°„åˆ° FROM å­å¥
WHERE user_id = :current_user
  AND timestamp > now() - interval '24 hours'
```

**ä¸åŒæ•°æ®æºçš„entityæ˜ å°„ï¼š**

```yaml
# 1. PostgreSQL - entity = è¡¨å
datasource: postgresql_events
entity: events                # SELECT * FROM events

# 2. ClickHouse - entity = è¡¨å
datasource: clickhouse_events
entity: events                # SELECT * FROM events

# 3. Neo4j - entityå¯èƒ½è¡¨ç¤ºèŠ‚ç‚¹æ ‡ç­¾ï¼ˆéœ€è¦è®¾è®¡å†³å®šï¼‰
datasource: neo4j_graph
entity: events                # MATCH (e:events) æˆ– MATCH ()-[r:events]->()
# æˆ–è€…ä¸ä½¿ç”¨entityï¼Œç›´æ¥åœ¨æŸ¥è¯¢é€»è¾‘ä¸­æŒ‡å®š

# 4. Redis - ä¸éœ€è¦entity
datasource: redis_features
# æ²¡æœ‰entityå­—æ®µï¼Œç›´æ¥é€šè¿‡keyè®¿é—®

# 5. Expression - ä¸éœ€è¦entity
type: expression
# æ²¡æœ‰entityå­—æ®µï¼Œä¸è®¿é—®æ•°æ®æº
```

**è®¾è®¡å»ºè®®ï¼š**

å¯¹äºNeo4jå›¾æ•°æ®åº“ï¼Œå¯ä»¥è€ƒè™‘ä¸¤ç§æ–¹æ¡ˆï¼š

**æ–¹æ¡ˆ1ï¼šä½¿ç”¨ `entity` è¡¨ç¤ºèŠ‚ç‚¹æ ‡ç­¾**
```yaml
datasource: neo4j_graph
entity: User                  # èŠ‚ç‚¹æ ‡ç­¾
dimension: user_id
dimension2: device_id
```

**æ–¹æ¡ˆ2ï¼šä¸ä½¿ç”¨ `entity`ï¼Œåœ¨datasourceé…ç½®ä¸­æŒ‡å®š**
```yaml
datasource: neo4j_graph       # datasourceé…ç½®ä¸­å·²æŒ‡å®šè¦æŸ¥è¯¢çš„èŠ‚ç‚¹/å…³ç³»ç±»å‹
dimension: user_id
dimension2: device_id
# ä¸éœ€è¦entityå­—æ®µ
```

### å„ç±»å‹ç‰¹æœ‰å­—æ®µ

**State ç‰¹æœ‰:**
- `current_value` - å½“å‰å€¼ï¼ˆç”¨äºå¯¹æ¯”ï¼‰

**Sequence ç‰¹æœ‰:**
- `reset_when` - é‡ç½®æ¡ä»¶
- `order_by` - æ’åºå­—æ®µ
- `baseline_window` - åŸºçº¿çª—å£ï¼ˆä»…ç”¨äº anomaly_score ç­‰éœ€è¦å†å²å¯¹æ¯”çš„æ–¹æ³•ï¼‰
- `aggregation` - çª—å£å†…çš„èšåˆæ–¹å¼
- `pattern` - äº‹ä»¶æ¨¡å¼åŒ¹é…
- `window_size` - ç§»åŠ¨å¹³å‡çª—å£å¤§å°

**Graph ç‰¹æœ‰:**
- `dimension2` - ç¬¬äºŒç»´åº¦ï¼ˆå…³è”ç»´åº¦ï¼Œå¦‚device_idå…³è”åˆ°user_idï¼‰
- `dimension_value2` - ç¬¬äºŒä¸ªç»´åº¦å€¼ï¼ˆä»…ç”¨äºéœ€è¦ä¸¤ä¸ªèŠ‚ç‚¹çš„æ–¹æ³•ï¼Œå¦‚ shared_entity_count, network_distanceï¼‰

**Expression ç‰¹æœ‰:**
- `expression` - è¡¨è¾¾å¼å­—ç¬¦ä¸²
- `depends_on` - ä¾èµ–çš„ç‰¹å¾åˆ—è¡¨
- `model` / `inputs` / `output` - MLæ¨¡å‹é…ç½®

**Lookup ç‰¹æœ‰:**
- `key` - Redis keyæ¨¡æ¿
- `fallback` - é»˜è®¤å€¼

### ç»Ÿä¸€å®ç°å¯è¡Œæ€§åˆ†æ

| ç±»å‹ | DSLä¸€è‡´æ€§ | å¯ç»Ÿä¸€å®ç°ï¼Ÿ | å»ºè®® |
|------|-----------|-------------|------|
| **Aggregation** | âœ… é«˜åº¦ä¸€è‡´ | âœ… æ˜¯ | ä¸€ä¸ªExecutorå¤„ç†æ‰€æœ‰method |
| **State** | âœ… è¾ƒä¸€è‡´ | âœ… æ˜¯ | ä¸€ä¸ªExecutorå¤„ç†æ‰€æœ‰method |
| **Sequence** | âš ï¸ ä¸­ç­‰ | âš ï¸ éƒ¨åˆ† | ç®€å•çš„å¯ç»Ÿä¸€ï¼Œå¤æ‚çš„(pattern)éœ€å•ç‹¬å¤„ç† |
| **Graph** | âš ï¸ å­—æ®µå·®å¼‚ | âœ… æ˜¯ | ä¸€ä¸ªExecutorï¼Œä½†å­—æ®µåä¸åŒ |
| **Expression** | âœ… ç®€å•ä¸€è‡´ | âœ… æ˜¯ | æ ¹æ®methodåˆ†å‘ï¼šexpression vs ml_model |
| **Lookup** | âœ… æœ€ç®€å• | âœ… æ˜¯ | ç›´æ¥key-valueæŸ¥è¯¢ |

### å®ç°å»ºè®®

```rust
// 1. Aggregation - é«˜åº¦ç»Ÿä¸€ âœ…
impl AggregationExecutor {
    fn execute(&self, method: AggregationType, config: AggregationConfig) -> Result<Value> {
        // æ‰€æœ‰methodå…±äº«ï¼šæ—¶é—´çª—å£ã€ç»´åº¦åˆ†ç»„ã€æ¡ä»¶è¿‡æ»¤
        // åªæœ‰èšåˆå‡½æ•°ä¸åŒï¼šCOUNT/SUM/AVG/MAX/MIN/DISTINCT...
    }
}

// 2. State - è¾ƒç»Ÿä¸€ âœ…
impl StateExecutor {
    fn execute(&self, method: StateQueryType, config: StateConfig) -> Result<Value> {
        // å…±äº«ï¼šç»´åº¦ã€åŸºçº¿çª—å£
        // å·®å¼‚ï¼šz_scoreéœ€è¦current_valueï¼Œtimezone_consistencyéœ€è¦expected_timezone
    }
}

// 3. Sequence - éƒ¨åˆ†ç»Ÿä¸€ âš ï¸
impl SequenceExecutor {
    fn execute(&self, method: SequenceAnalysisType, config: SequenceConfig) -> Result<Value> {
        match method {
            ConsecutiveCount => { /* ç®€å•ï¼Œå¯ç»Ÿä¸€ */ }
            PercentChange => { /* éœ€è¦åŒçª—å£ï¼Œå¯ç»Ÿä¸€ */ }
            MovingAverage => { /* éœ€è¦window_sizeï¼Œå¯ç»Ÿä¸€ */ }
            EventPatternMatch => { /* å¤æ‚ï¼Œéœ€è¦patternåŒ¹é…å¼•æ“ */ }
        }
    }
}

// 4. Graph - å¯ç»Ÿä¸€ âœ…
impl GraphExecutor {
    fn execute(&self, method: GraphAnalysisType, config: GraphConfig) -> Result<Value> {
        // ä½¿ç”¨ç»Ÿä¸€çš„dimension/dimension_valueå­—æ®µ
        // dimension2è¡¨ç¤ºç¬¬äºŒç»´åº¦ï¼ˆå…³è”ç»´åº¦ï¼‰
    }
}

// 5. Expression - ç®€å•ç»Ÿä¸€ âœ…
impl ExpressionExecutor {
    fn execute(&self, method: ExpressionType, config: ExpressionConfig) -> Result<Value> {
        match method {
            CustomExpression => { /* è¡¨è¾¾å¼å¼•æ“ */ }
            MLModelScore => { /* æ¨¡å‹æ¨ç† */ }
        }
    }
}

// 6. Lookup - æœ€ç®€å• âœ…
impl LookupExecutor {
    fn execute(&self, config: LookupConfig) -> Result<Value> {
        // ç›´æ¥Redis GETæ“ä½œ
        self.redis.get(&config.key).or(config.fallback)
    }
}
```

### æ€»ç»“

âœ… **æ‰€æœ‰ç±»å‹éƒ½å¯ä»¥ç”¨ç»Ÿä¸€çš„Executorå®ç°**
- Aggregation, State, Expression, Lookup: é«˜åº¦ç»Ÿä¸€
- Graph: é«˜åº¦ç»Ÿä¸€ï¼ˆå·²ä½¿ç”¨ä¸€è‡´çš„å­—æ®µå‘½åï¼‰
- Sequence: ç®€å•methodå¯ç»Ÿä¸€ï¼Œå¤æ‚çš„(pattern)éœ€ç‰¹æ®Šå¤„ç†

âœ… **DSLå‘½åä¸€è‡´æ€§**
- æ‰€æœ‰ç±»å‹ç»Ÿä¸€ä½¿ç”¨ `dimension` / `dimension_value` ä½œä¸ºä¸»ç»´åº¦
- Graphç±»å‹ä½¿ç”¨ `dimension2` è¡¨ç¤ºç¬¬äºŒç»´åº¦ï¼ˆå…³è”ç»´åº¦ï¼‰
- ä¿æŒè·¨ç±»å‹çš„å­—æ®µå‘½åä¸€è‡´æ€§

---

### 2. State Operators ğŸ”´ Planned
> **Rust Implementation:** `StateExecutor::execute(op: StateQueryType, config: StateConfig)`
>
> **Status:** ğŸ”´ Not yet implemented - all operators are in development roadmap
>
> âš ï¸ **Important**: This section describes planned functionality. The implementation is in development and not currently available.
>
> **Design Pattern:** Statistical comparison and baseline analysis
>


**Planned:**
- `z_score` - Statistical z-score compared to baseline
  - *Example: å½“å‰äº¤æ˜“é‡‘é¢Z-scoreä¸º2.8ï¼Œå¼‚å¸¸åé«˜*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - å¼‚å¸¸äº¤æ˜“æ£€æµ‹ï¼šç”¨æˆ·äº¤æ˜“é‡‘é¢Z-score > 3ï¼Œå¯èƒ½è¢«ç›—åˆ·
    - ç™»å½•é¢‘ç‡å¼‚å¸¸ï¼šç™»å½•é¢‘ç‡Z-score > 2.5ï¼Œå¯èƒ½æ˜¯æš´åŠ›ç ´è§£
    - åŠ¨æ€é˜ˆå€¼ï¼šæ ¹æ®Z-scoreè‡ªåŠ¨è°ƒæ•´é£æ§ç­–ç•¥ï¼Œè€Œéå›ºå®šé˜ˆå€¼
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: zscore_userid_txn_amt
      type: state
      method: z_score
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: amount
      current_value: "{event.amount}"
      window: 90d
      when: type == "transaction"         # Database field (no prefix)
    ```

- `deviation_from_baseline` - Compare to historical average
  - *Example: å½“å‰ç™»å½•é¢‘ç‡æ¯”å†å²å¹³å‡é«˜150%*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - è¡Œä¸ºçªå˜æ£€æµ‹ï¼šç”¨æˆ·æ—¥å‡ç™»å½•2æ¬¡ï¼Œä»Šå¤©ç™»å½•20æ¬¡ï¼Œåç¦»900%
    - æ¶ˆè´¹ä¹ æƒ¯å˜åŒ–ï¼šå†å²æ—¥å‡æ¶ˆè´¹Â¥200ï¼Œä»Šå¤©æ¶ˆè´¹Â¥5000ï¼Œåç¦»2400%
    - è´¦å·æ¥ç®¡ï¼šè¡Œä¸ºæ¨¡å¼çªç„¶åç¦»åŸºçº¿ï¼Œå¯èƒ½è¢«ä»–äººæ§åˆ¶
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: deviation_userid_login_freq
      type: state
      method: deviation_from_baseline
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: login_count
      current_value: "{event.current_login_count}"
      window: 90d
      when: type == "login"               # Database field (no prefix)
    ```

- `percentile_rank` - Rank compared to history
  - *Example: å½“å‰äº¤æ˜“é‡‘é¢å¤„äºå†å²ç¬¬92ç™¾åˆ†ä½*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - å¤§é¢äº¤æ˜“éªŒè¯ï¼šå½“å‰äº¤æ˜“é‡‘é¢è¶…è¿‡å†å²P95ï¼Œéœ€è¦äºŒæ¬¡éªŒè¯
    - å¼‚å¸¸æ´»è·ƒåº¦ï¼šå½“å‰ç™»å½•é¢‘ç‡è¶…è¿‡å†å²P99ï¼Œå¯èƒ½å¼‚å¸¸
    - é£é™©åˆ†çº§ï¼šP0-P50ä½é£é™©ï¼ŒP50-P90ä¸­é£é™©ï¼ŒP90+é«˜é£é™©
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: pctrank_userid_txn_amt
      type: state
      method: percentile_rank
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: amount
      current_value: "{event.amount}"
      window: 90d
      when: type == "transaction"         # Database field (no prefix)
    ```

- `is_outlier` - Statistical outlier detection
  - *Example: å½“å‰è¡Œä¸ºåˆ¤å®šä¸ºç»Ÿè®¡å¼‚å¸¸å€¼ï¼ˆtrueï¼‰*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - è‡ªåŠ¨å¼‚å¸¸æ ‡è®°ï¼šç»Ÿè®¡å­¦åˆ¤æ–­ä¸ºå¼‚å¸¸å€¼ï¼Œç›´æ¥è§¦å‘äººå·¥å®¡æ ¸
    - æ¬ºè¯ˆæ£€æµ‹ï¼šäº¤æ˜“é‡‘é¢/é¢‘ç‡/åœ°ç‚¹ç­‰å¤šç»´åº¦å¼‚å¸¸å€¼æ£€æµ‹
    - æœºå™¨å­¦ä¹ ç‰¹å¾ï¼šå¼‚å¸¸å€¼æ ‡è®°ä½œä¸ºMLæ¨¡å‹è¾“å…¥ç‰¹å¾
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: outlier_userid_txn_amt
      type: state
      method: is_outlier
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: amount
      current_value: "{event.amount}"
      window: 90d
      when: type == "transaction"         # Database field (no prefix)
    ```

```rust
enum StateQueryType {
    ZScore,
    DeviationFromBaseline,
    PercentileRank,
    IsOutlier,
}

// Unified executor for statistical comparison operators:
// - Baseline computation from historical data
// - Statistical analysis (z-score, percentile, outlier detection)
// - Time-based pattern analysis
impl StateExecutor {
    fn execute(&self, op: StateQueryType, config: &StateConfig) -> Result<Value>
}
```

### 3. Sequence Operators ğŸ”´ Planned
> **Rust Implementation:** `SequenceAnalyzer::analyze(op: SequenceAnalysisType, config: SequenceConfig)`
>
> **Status:** ğŸ”´ Not yet implemented - all operators are in development roadmap
>
> âš ï¸ **Important**: This section describes planned functionality. The implementation is in development and not currently available.
>
> **Design Pattern:** Pipeline-based analyzer with composable stages

**Planned:**
- `consecutive_count` - Count consecutive occurrences
  - *Example: ç”¨æˆ·è¿ç»­å¤±è´¥ç™»å½•3æ¬¡*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - æš´åŠ›ç ´è§£ï¼šè¿ç»­å¤±è´¥ç™»å½•â‰¥5æ¬¡ï¼Œé”å®šè´¦æˆ·15åˆ†é’Ÿ
    - æ”¯ä»˜å¤±è´¥ï¼šè¿ç»­3æ¬¡æ”¯ä»˜å¤±è´¥ï¼Œå¯èƒ½å¡è¢«å†»ç»“æˆ–ä½™é¢ä¸è¶³
    - å¼‚å¸¸æ“ä½œï¼šè¿ç»­10æ¬¡å¿«é€Ÿç‚¹å‡»ï¼Œå¯èƒ½æ˜¯è„šæœ¬æ”»å‡»
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: consec_userid_login_1h_failed
      type: sequence
      method: consecutive_count
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      window: 1h
      when:
        all:
          - type == "login"               # Database field (no prefix)
          - status == "failed"             # Database field (no prefix)
      reset_when: status == "success"     # Database field (no prefix)
    ```

- `streak` - Longest streak of condition
  - *Example: ç”¨æˆ·è¿ç»­7å¤©æ¯å¤©éƒ½æœ‰äº¤æ˜“ï¼ˆæ´»è·ƒåº¦é«˜ï¼‰*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - ç”¨æˆ·æ´»è·ƒåº¦ï¼šè¿ç»­æ´»è·ƒ7å¤©çš„ç”¨æˆ·ï¼Œæµå¤±é£é™©ä½
    - åˆ·å•æ£€æµ‹ï¼šè¿ç»­30å¤©æ¯å¤©éƒ½æœ‰è®¢å•ï¼Œä¸”é‡‘é¢ç›¸ä¼¼ï¼Œç–‘ä¼¼åˆ·å•
    - ä¹ æƒ¯å…»æˆï¼šè¿ç»­3å¤©ä½¿ç”¨æŸåŠŸèƒ½ï¼Œæ¨èç›¸å…³æœåŠ¡
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: streak_userid_daily_txn_30d
      type: sequence
      method: streak
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      window: 30d
      when: type == "transaction"         # Database field (no prefix)
      aggregation: count_per_day
      reset_when: count_per_day == 0
    ```

- `sequence_match` - Match event sequences
  - *Example: æ£€æµ‹åˆ°"ä¿®æ”¹å¯†ç â†’ç™»å½•â†’å¤§é¢è½¬è´¦"å¯ç–‘åºåˆ—*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - è´¦æˆ·æ¥ç®¡ï¼šå¯†ç é‡ç½®â†’ä¿®æ”¹é‚®ç®±â†’å¤§é¢è½¬è´¦ï¼ˆ15åˆ†é’Ÿå†…ï¼‰ï¼Œé«˜é£é™©
    - æ¬ºè¯ˆæ¨¡å¼ï¼šæ³¨å†Œâ†’å®åè®¤è¯â†’ç”³è¯·è´·æ¬¾â†’æç°ï¼ˆ1å°æ—¶å†…ï¼‰ï¼Œç–‘ä¼¼æ¬ºè¯ˆ
    - æ­£å¸¸æµç¨‹ï¼šæµè§ˆå•†å“â†’åŠ å…¥è´­ç‰©è½¦â†’ç»“ç®—â†’æ”¯ä»˜ï¼Œè½¬åŒ–æ¼æ–—åˆ†æ
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: seq_userid_account_takeover_pattern
      type: sequence
      method: sequence_match
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      window: 1h
      pattern:
        - type == "password_reset"                     # Database field
        - type == "email_change"                       # Database field
        - type == "transaction" AND amount > 10000     # Database fields
      order_by: timestamp
    ```

- `pattern_frequency` - Frequency of specific patterns
  - *Example: "ç™»å½•â†’æµè§ˆâ†’åŠ è´­â†’æ”¯ä»˜"å®Œæ•´è·¯å¾„å‡ºç°5æ¬¡*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - åˆ·å•æ£€æµ‹ï¼šç›¸åŒæ“ä½œåºåˆ—é‡å¤å‡ºç°>10æ¬¡ï¼Œç–‘ä¼¼åˆ·å•
    - ç”¨æˆ·è¡Œä¸ºåˆ†æï¼šé«˜ä»·å€¼ç”¨æˆ·çš„å…¸å‹è·¯å¾„é¢‘ç‡
    - å¼‚å¸¸æ¨¡å¼ï¼šå¼‚å¸¸æ“ä½œåºåˆ—é¢‘ç¹å‡ºç°ï¼Œå¯èƒ½æ˜¯æ”»å‡»
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: freq_userid_purchase_pattern_7d
      type: sequence
      method: pattern_frequency
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      window: 7d
      pattern:
        - type == "login"                              # Database field
        - type == "browse"                             # Database field
        - type == "add_to_cart"                        # Database field
        - type == "payment"                            # Database field
      order_by: timestamp
    ```

- `trend` - Calculate trend (increasing/decreasing/stable)
  - *Example: ç”¨æˆ·äº¤æ˜“é‡‘é¢å‘ˆä¸Šå‡è¶‹åŠ¿ï¼ˆ+15%/å‘¨ï¼‰*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - æ¶ˆè´¹è¶‹åŠ¿ï¼šäº¤æ˜“é‡‘é¢æŒç»­ä¸Šå‡ï¼Œç”¨æˆ·ä»·å€¼å¢é•¿
    - é£é™©è¶‹åŠ¿ï¼šå¤±è´¥äº¤æ˜“æ¯”ä¾‹ä¸Šå‡è¶‹åŠ¿ï¼Œå¯èƒ½å¡å‡ºé—®é¢˜
    - å¼‚å¸¸æ£€æµ‹ï¼šç™»å½•é¢‘ç‡çªç„¶ä¸Šå‡è¶‹åŠ¿ï¼ˆæ–œç‡é™¡å¢ï¼‰ï¼Œå¯èƒ½è¢«ç›—å·
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: trend_userid_txn_amt_30d
      type: sequence
      method: trend
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: amount
      window: 30d
      when: type == "transaction"         # Database field (no prefix)
      aggregation: sum_per_week
    ```

- `percent_change` - Percentage change between windows
  - *Example: æœ¬å‘¨äº¤æ˜“æ¬¡æ•°æ¯”ä¸Šå‘¨å¢åŠ 120%*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - è¡Œä¸ºçªå˜ï¼šæœ¬å‘¨äº¤æ˜“æ¯”ä¸Šå‘¨å¢åŠ 500%ï¼Œå¼‚å¸¸æ´»è·ƒ
    - ä¿ƒé”€æ•ˆæœï¼šæ´»åŠ¨æœŸé—´äº¤æ˜“é‡å¢åŠ 200%ï¼Œæ•ˆæœæ˜¾è‘—
    - ä¼‘çœ å”¤é†’ï¼šæœ¬å‘¨äº¤æ˜“æ¯”ä¸Šå‘¨å¢é•¿ä»0åˆ°10ï¼Œè´¦æˆ·è¢«é‡æ–°æ¿€æ´»
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: pctchg_userid_txn_cnt_week
      type: sequence
      method: percent_change
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      window: 7d
      when: type == "transaction"         # Database field (no prefix)
      aggregation: count
    ```
  - **è®¡ç®—é€»è¾‘**:
    - å½“å‰çª—å£ï¼š[now - 7d, now]
    - åŸºçº¿çª—å£ï¼š[now - 14d, now - 7d]
    - ç™¾åˆ†æ¯”å˜åŒ– = (å½“å‰çª—å£å€¼ - åŸºçº¿çª—å£å€¼) / åŸºçº¿çª—å£å€¼ Ã— 100%

- `rate_of_change` - Rate of change over time
  - *Example: ç”¨æˆ·ç™»å½•é¢‘ç‡å¢é•¿ç‡ä¸º+5æ¬¡/å¤©*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - åŠ é€Ÿåº¦æ£€æµ‹ï¼šäº¤æ˜“é¢‘ç‡å¢é•¿ç‡ä»1æ¬¡/å¤©åŠ é€Ÿåˆ°10æ¬¡/å¤©ï¼Œå¼‚å¸¸
    - æ¸è¿›å¼æ”»å‡»ï¼šå¤±è´¥ç™»å½•ç‡æ¯å°æ—¶å¢åŠ 2æ¬¡ï¼Œé€æ­¥å‡çº§æ”»å‡»
    - è¶‹åŠ¿é¢„è­¦ï¼šè®¢å•é‡ä¸‹é™ç‡-3å•/å¤©ï¼Œå¯èƒ½æµå¤±
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: roc_userid_login_freq_7d
      type: sequence
      method: rate_of_change
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: login_count
      window: 7d
      when: type == "login"               # Database field (no prefix)
      aggregation: count_per_day
    ```

- `anomaly_score` - Statistical anomaly detection
  - *Example: åºåˆ—å¼‚å¸¸è¯„åˆ†8.5/10ï¼Œé«˜åº¦å¯ç–‘*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - ç»¼åˆå¼‚å¸¸æ£€æµ‹ï¼šåŸºäºæ—¶åºæ¨¡å‹è®¡ç®—å¼‚å¸¸åˆ†æ•°ï¼Œ>7åˆ†è§¦å‘å®¡æ ¸
    - è´¦æˆ·è¡Œä¸ºç”»åƒï¼šè¡Œä¸ºåºåˆ—ä¸å†å²æ¨¡å¼å·®å¼‚åº¦è¯„åˆ†
    - æ¬ºè¯ˆæ¦‚ç‡ï¼šåºåˆ—å¼‚å¸¸åˆ†æ•°ä½œä¸ºæ¬ºè¯ˆæ¨¡å‹è¾“å…¥ç‰¹å¾
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: anomaly_userid_behavior_score_7d
      type: sequence
      method: anomaly_score
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: event_type
      window: 7d
      baseline_window: 90d
      order_by: timestamp
    ```

- `moving_average` - Moving average over window
  - *Example: ç”¨æˆ·7å¤©ç§»åŠ¨å¹³å‡äº¤æ˜“é¢ Â¥800/å¤©*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - å¹³æ»‘è¶‹åŠ¿åˆ†æï¼š7æ—¥ç§»åŠ¨å¹³å‡æ¶ˆé™¤æ—¥å¸¸æ³¢åŠ¨ï¼Œè§‚å¯ŸçœŸå®è¶‹åŠ¿
    - å¼‚å¸¸æ£€æµ‹ï¼šå½“å‰äº¤æ˜“é¢è¶…è¿‡7æ—¥ç§»åŠ¨å¹³å‡3å€ï¼Œå¼‚å¸¸
    - åŠ¨æ€åŸºçº¿ï¼šä½¿ç”¨ç§»åŠ¨å¹³å‡ä½œä¸ºåŠ¨æ€åŸºçº¿ï¼Œè‡ªé€‚åº”ç”¨æˆ·è¡Œä¸ºå˜åŒ–
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: ma7_userid_txn_amt
      type: sequence
      method: moving_average
      datasource: clickhouse_events
      entity: events
      dimension: user_id
      dimension_value: "{event.user_id}"
      field: amount
      window: 7d
      when: type == "transaction"         # Database field (no prefix)
      window_size: 7
    ```

```rust
enum SequenceAnalysisType {
    ConsecutiveCount, Streak, SequenceMatch { pattern: Vec<Pattern> },
    PatternFrequency, Trend, PercentChange, RateOfChange, AnomalyScore,
    MovingAverage { window_size: usize },
}

// Pipeline-based analyzer - operators share:
// - Event ordering
// - Windowing logic
// - Pattern matching engine
impl SequenceAnalyzer {
    fn analyze(&self, op: SequenceAnalysisType, config: &SequenceConfig) -> Result<Value>
}

// Note: Session-based analysis (session_count, session_duration, events_per_session)
// should be implemented using Aggregation operators with session_id provided by
// the business system. Examples:
//   - session_count â†’ distinct(session_id)
//   - session_duration â†’ avg(session_duration) where session_duration is provided
//   - events_per_session â†’ expression: total_events / distinct_sessions
```

### 4. Graph Operators ğŸ”´ Planned
> **Rust Implementation:** `GraphAnalyzer::analyze(op: GraphAnalysisType, config: GraphConfig)`
>
> **Status:** ğŸ”´ Not yet implemented - all operators are in development roadmap
>
> âš ï¸ **Important**: This section describes planned functionality. The implementation is in development and not currently available.
>
> **Design Pattern:** Graph-based analyzer with lazy graph construction

**å­—æ®µè¯­ä¹‰è¯´æ˜ï¼š**

Graphç±»å‹åˆ†æäºŒéƒ¨å›¾ï¼ˆBipartite Graphï¼‰ç»“æ„ï¼Œå…¶ä¸­ï¼š
- `dimension` - ä¸»å®ä½“ç±»å‹ï¼ˆå¦‚ user_idï¼‰
- `dimension2` - å…³è”å®ä½“ç±»å‹ï¼ˆå¦‚ device_idï¼‰
- å½¢æˆå›¾ç»“æ„ï¼šUser <--> Device <--> User <--> Device

**å•èŠ‚ç‚¹æ–¹æ³•**ï¼ˆå¦‚ graph_centrality, community_sizeï¼‰ï¼š
- `dimension_value` - è¦åˆ†æçš„èŠ‚ç‚¹
- `dimension2` - è¯¥èŠ‚ç‚¹å¦‚ä½•ä¸å…¶ä»–èŠ‚ç‚¹å…³è”

**åŒèŠ‚ç‚¹æ–¹æ³•**ï¼ˆå¦‚ shared_entity_count, network_distanceï¼‰ï¼š
- `dimension_value` - èµ·ç‚¹/æºèŠ‚ç‚¹
- `dimension_value2` - ç»ˆç‚¹/ç›®æ ‡èŠ‚ç‚¹ï¼ˆåŒä¸€ç±»å‹ï¼‰
- `dimension2` - ä¸¤ä¸ªèŠ‚ç‚¹é€šè¿‡ä»€ä¹ˆå»ºç«‹è¿æ¥ï¼ˆä¸­é—´èŠ‚ç‚¹ç±»å‹ï¼‰

**Planned:**
- `graph_centrality` - Network centrality score
  - *Example: è®¾å¤‡åœ¨ç”¨æˆ·ç½‘ç»œä¸­å¿ƒåº¦0.65ï¼Œå¯èƒ½æ˜¯å…±äº«è®¾å¤‡*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - æ ¸å¿ƒèŠ‚ç‚¹è¯†åˆ«ï¼šä¸­å¿ƒåº¦>0.8çš„è®¾å¤‡ï¼Œå¯èƒ½æ˜¯æ¬ºè¯ˆå›¢ä¼™æ ¸å¿ƒè®¾å¤‡
    - é£é™©æºå®šä½ï¼šé«˜ä¸­å¿ƒåº¦è´¦æˆ·è¢«æ ‡è®°æ¬ºè¯ˆï¼Œå…³è”è´¦æˆ·éœ€å®¡æŸ¥
    - é»‘äº§è¯†åˆ«ï¼šä¸­å¿ƒåº¦å¼‚å¸¸é«˜çš„IPï¼Œå¯èƒ½æ˜¯é»‘äº§æ“ä½œèŠ‚ç‚¹
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: centrality_device_in_user_network
      type: graph
      method: graph_centrality
      datasource: neo4j_graph
      dimension: device_id
      dimension_value: "{event.device_id}"
      dimension2: user_id
      window: 30d
    ```

- `community_size` - Size of connected component
  - *Example: è¯¥ç”¨æˆ·æ‰€åœ¨æ¬ºè¯ˆå›¢ä¼™ç¤¾åŒºè§„æ¨¡23äºº*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - å›¢ä¼™æ¬ºè¯ˆï¼šç¤¾åŒºè§„æ¨¡>20äººä¸”äº¤æ˜“æ¨¡å¼ç›¸ä¼¼ï¼Œç–‘ä¼¼æ¬ºè¯ˆå›¢ä¼™
    - æ´—é’±ç½‘ç»œï¼šèµ„é‡‘åœ¨å¤§ç¤¾åŒºå†…å¾ªç¯æµè½¬ï¼Œå¯èƒ½æ´—é’±
    - æ­£å¸¸ç¤¾äº¤ï¼šå°ç¤¾åŒº(<5äºº)ä¸”è¡Œä¸ºæ­£å¸¸ï¼Œå¯èƒ½æ˜¯å®¶åº­/æœ‹å‹
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: community_size_userid_device_network
      type: graph
      method: community_size
      datasource: neo4j_graph
      dimension: user_id
      dimension_value: "{event.user_id}"
      dimension2: device_id
      window: 90d
    ```

- `shared_entity_count` - Count shared connections
  - *Example: ä¸¤ä¸ªç”¨æˆ·å…±äº«5ä¸ªç›¸åŒè®¾å¤‡*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - è™šå‡è´¦æˆ·ï¼šä¸¤ä¸ªè´¦æˆ·å…±äº«>3ä¸ªè®¾å¤‡ï¼Œå¯èƒ½æ˜¯åŒä¸€äººå¤šè´¦æˆ·
    - å…³è”æ¬ºè¯ˆï¼šå¤šä¸ªé«˜é£é™©è´¦æˆ·å…±äº«è®¾å¤‡/IPï¼ŒååŒæ¬ºè¯ˆ
    - å®¶åº­è¯†åˆ«ï¼šå…±äº«2ä¸ªè®¾å¤‡(æ‰‹æœº+ç”µè„‘)ï¼Œå¯èƒ½æ˜¯å®¶åº­æˆå‘˜
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: shared_devices_between_users
      type: graph
      method: shared_entity_count
      datasource: neo4j_graph
      dimension: user_id                      # èŠ‚ç‚¹ç±»å‹
      dimension_value: "{event.user_id}"      # èŠ‚ç‚¹1ï¼ˆæºï¼‰
      dimension_value2: "{event.target_user_id}"  # èŠ‚ç‚¹2ï¼ˆç›®æ ‡ï¼‰
      dimension2: device_id                   # å…±äº«å®ä½“ç±»å‹
      window: 30d
    ```
  - **å­—æ®µè¯´æ˜**:
    - `dimension: user_id` - ä¸»å®ä½“ç±»å‹ï¼ˆä¸¤ä¸ªèŠ‚ç‚¹éƒ½æ˜¯Userï¼‰
    - `dimension_value` - User1
    - `dimension_value2` - User2
    - `dimension2: device_id` - **å…±äº«çš„ä¸­é—´èŠ‚ç‚¹ç±»å‹**
    - è®¡ç®—ç»“æœï¼šUser1å’ŒUser2å…±äº«å¤šå°‘ä¸ªDevice
  - **å›¾ç»“æ„ç¤ºä¾‹**:
    ```
    User1 --ä½¿ç”¨--> Device1 <--ä½¿ç”¨-- User2
          --ä½¿ç”¨--> Device2 <--ä½¿ç”¨--
          --ä½¿ç”¨--> Device3 <--ä½¿ç”¨--

    ç»“æœ = 3ï¼ˆå…±äº«3ä¸ªè®¾å¤‡ï¼‰
    ```
    - User1å’ŒUser2éƒ½æ˜¯ `user_id` ç±»å‹ï¼ˆdimensionï¼‰
    - Device1/2/3æ˜¯ `device_id` ç±»å‹ï¼ˆdimension2ï¼Œå…±äº«èŠ‚ç‚¹ï¼‰
    - æŸ¥æ‰¾ï¼šæœ‰å¤šå°‘ä¸ªDeviceåŒæ—¶è¿æ¥åˆ°User1å’ŒUser2

- `network_distance` - Distance between entities in graph
  - *Example: ä¸¤ä¸ªè´¦æˆ·çš„ç½‘ç»œè·ç¦»ä¸º3è·³ï¼ˆé—´æ¥å…³è”ï¼‰*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - é£é™©ä¼ æ’­ï¼šè·ç¦»å·²çŸ¥æ¬ºè¯ˆè´¦æˆ·â‰¤2è·³ï¼Œéœ€è¦å®¡æŸ¥
    - å…³è”åˆ†æï¼šè™½æ— ç›´æ¥å…³è”ï¼Œä½†ç½‘ç»œè·ç¦»â‰¤3è·³ï¼Œé—´æ¥å…³è”
    - ç¤¾äº¤æ¨èï¼šç½‘ç»œè·ç¦»2-3è·³çš„ç”¨æˆ·ï¼Œå¯èƒ½æœ‰å…±åŒå…´è¶£
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: network_dist_to_fraud_account
      type: graph
      method: network_distance
      datasource: neo4j_graph
      dimension: user_id                      # èŠ‚ç‚¹ç±»å‹
      dimension_value: "{event.user_id}"      # èµ·ç‚¹èŠ‚ç‚¹
      dimension_value2: "{known_fraud_user_id}"   # ç»ˆç‚¹èŠ‚ç‚¹
      dimension2: device_id                   # è¿æ¥è·¯å¾„
      window: 90d
    ```
  - **å­—æ®µè¯´æ˜**:
    - `dimension: user_id` - ä¸»å®ä½“ç±»å‹ï¼ˆèµ·ç‚¹å’Œç»ˆç‚¹éƒ½æ˜¯Userï¼‰
    - `dimension_value` - èµ·ç‚¹User
    - `dimension_value2` - ç»ˆç‚¹User
    - `dimension2: device_id` - **ä¸­é—´è¿æ¥èŠ‚ç‚¹ç±»å‹**ï¼ˆä¸æ˜¯ç»ˆç‚¹ç±»å‹ï¼ï¼‰
    - è®¡ç®—ç»“æœï¼šä»èµ·ç‚¹åˆ°ç»ˆç‚¹çš„æœ€çŸ­è·³æ•°
  - **å›¾ç»“æ„ç¤ºä¾‹**:
    ```
    UserA --ä½¿ç”¨--> Device1 <--ä½¿ç”¨-- UserC --ä½¿ç”¨--> Device2 <--ä½¿ç”¨-- UserB
    èµ·ç‚¹                                                              ç»ˆç‚¹

    è·³æ•° = 2è·³ï¼ˆUserA -> Device1 -> UserC -> Device2 -> UserBï¼‰
    ```
    - UserAå’ŒUserBéƒ½æ˜¯ `user_id` ç±»å‹ï¼ˆdimensionï¼‰
    - Device1å’ŒDevice2æ˜¯ `device_id` ç±»å‹ï¼ˆdimension2ï¼Œä¸­é—´è¿æ¥ï¼‰
    - å›¾éå†ï¼šUser -> Device -> User -> Device -> User

```rust
enum GraphAnalysisType {
    // Network analysis (require graph traversal)
    Centrality, CommunitySize, SharedEntityCount, NetworkDistance,
}

// Graph analyzer focuses on true graph algorithms:
// - Graph construction and indexing (for network-based operators)
// - Graph traversal (BFS, DFS)
// - Graph algorithms (PageRank, community detection, shortest path)
//
// Note:
// - Entity linking (e.g., devices per IP) should use distinct() aggregation
impl GraphAnalyzer {
    fn analyze(&self, op: GraphAnalysisType, config: &GraphConfig) -> Result<Value>
}
```

### 5. Expression Operators ğŸŸ¢ Implemented
> **Rust Implementation:** `ExpressionEngine::evaluate(expr: ExpressionType, context: &FeatureContext)`
>
> **Status:** âœ… Production-ready | ğŸ“‹ ML model integration planned
>
> **Design Pattern:** Expression engine with pluggable evaluators
>
> **âš ï¸ Architecture Constraint:** Expression operators do NOT access raw data sources or define time windows; they ONLY consume results from other features.

**Implemented:**
- `expression` - Evaluate custom expressions using other features
  - *Example: è®¡ç®—ç™»å½•å¤±è´¥ç‡ = failed_count / total_count*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - å¤±è´¥ç‡è®¡ç®—ï¼šlogin_failure_rate = failed_login_count_1h / login_count_1h
    - å¤åˆè¯„åˆ†ï¼šrisk_score = 0.4 * transaction_anomaly + 0.3 * device_risk + 0.3 * location_risk
    - æ¯”ç‡åˆ†æï¼šlarge_transaction_ratio = transactions_above_1000 / total_transactions
    - è½¬åŒ–ç‡ï¼šconversion_rate = purchase_count / view_count
  - **YAMLç¤ºä¾‹**:
    ```yaml
    - name: rate_userid_login_failure
      type: expression
      method: expression
      expression: "failed_login_count_1h / login_count_1h"
      depends_on:
        - failed_login_count_1h
        - login_count_1h
    ```

```rust
enum ExpressionType {
    CustomExpression { expr: String },
    MlModelScore { model_id: String, inputs: Vec<String> },
    EmbeddingSimilarity { embedding_a: String, embedding_b: String },
    ClusteringLabel { algorithm: String },
    MlAnomalyScore { model_id: String },
}

// Expression engine - provides:
// - Expression parser
// - Feature dependency resolution
// - ML model integration
//
// IMPORTANT: ExpressionEngine only operates on pre-computed feature values,
// never directly accessing data sources or executing queries.
impl ExpressionEngine {
    fn evaluate(&self, expr: ExpressionType, context: &FeatureContext) -> Result<Value>
}
```

### 6. Lookup Operators ğŸŸ¢ Implemented
> **Rust Implementation:** `DataSource::get(key: &str) -> Result<Value>`
>
> **Status:** âœ… Production-ready
>
> **Design Pattern:** Simple key-value retrieval from Redis cache
>
> **âš ï¸ Architecture Constraint:** Lookup features do NOT perform any computation; they only retrieve pre-computed values.

**Implemented:**
- Direct key-value lookup from datasource
  - *Example: ä»RedisæŸ¥è¯¢ç”¨æˆ·90å¤©é£é™©è¯„åˆ†*
  - **å®é™…åº”ç”¨åœºæ™¯**:
    - æ‰¹é‡è®¡ç®—çš„é£é™©è¯„åˆ†ï¼šæ¯å¤©å‡Œæ™¨æ‰¹é‡è®¡ç®—ç”¨æˆ·é£é™©åˆ†æ•°ï¼Œå­˜å‚¨åœ¨Redis
    - ç”¨æˆ·ç»†åˆ†æ ‡ç­¾ï¼šæ•°æ®åˆ†æå›¢é˜Ÿç”Ÿæˆçš„ç”¨æˆ·åˆ†ç¾¤æ ‡ç­¾ï¼Œç¼“å­˜åœ¨Redis
    - è®¾å¤‡æŒ‡çº¹ï¼šå®‰å…¨å›¢é˜Ÿç»´æŠ¤çš„è®¾å¤‡ä¿¡èª‰åº“ï¼Œå­˜å‚¨åœ¨Redis
    - ç¼“å­˜çš„èšåˆç‰¹å¾ï¼šå®šæ—¶ä»»åŠ¡é¢„è®¡ç®—çš„èšåˆæŒ‡æ ‡ï¼ŒåŠ é€Ÿå®æ—¶æŸ¥è¯¢
  - **YAMLç¤ºä¾‹**:
    ```yaml
    # Redis lookup
    - name: user_risk_score_90d
      type: lookup
      datasource: redis_features
      key: "user_risk_score:{event.user_id}"
      fallback: 50
    ```

```rust
// Lookup features use simple datasource interface
// No complex executor needed - just key-value retrieval

impl FeatureExecutor {
    fn execute_lookup(&self, config: &LookupConfig) -> Result<Value> {
        let datasource = self.datasources.get(&config.datasource)?;

        match datasource.get(&config.key) {
            Ok(value) => Ok(value),
            Err(_) => Ok(config.fallback.clone().unwrap_or(Value::Null)),
        }
    }
}
```

---

## Architecture Benefits

This design provides:

1. **Code Reuse**: Common logic (time windows, filtering, caching) shared across operators
2. **Maintainability**: Adding new operators only requires extending enums, not creating new functions
3. **Performance**: Unified executors can optimize query plans and batch operations
4. **Type Safety**: Enum-based dispatch ensures compile-time operator validation
5. **Testability**: Each executor can be tested independently with all operator variants

---

## Data Source Configuration

Feature definitions reference data sources through the `datasource` field, which points to data source configurations defined in `repository/configs/datasources/`. This design provides:

- **Configuration Separation**: Data source credentials and connection details are managed independently
- **Environment Isolation**: Different environments (dev/staging/prod) can use different data source configurations
- **Security**: Sensitive information (passwords, API keys) managed via environment variables
- **Reusability**: Multiple features can reference the same data source

### Data Source Types

**Event/Transaction Data** (for real-time computation):
- `postgresql` - PostgreSQL for transactional and event data (used by Aggregation features)
- `clickhouse` - ClickHouse for high-volume event storage (used by State/Sequence features)

**Graph Data** (for network analysis):
- `neo4j` - Neo4j graph database for relationship and network analysis

**Pre-computed Features** (for lookups):
- `redis` - Redis for cached feature values

**Profile/Context Data:**
- Should be passed directly in the request payload, not queried via datasource

### Data Source Configuration Files

Data sources are defined in `repository/configs/datasources/` as YAML files:

**`repository/configs/datasources/postgresql_events.yaml`**:
```yaml
name: postgresql_events
type: postgresql
config:
  host: ${POSTGRES_HOST}
  port: 5432
  database: ${POSTGRES_DATABASE}
  user: ${POSTGRES_USER}
  password: ${POSTGRES_PASSWORD}
  sslmode: ${POSTGRES_SSLMODE}  # disable, require, verify-ca, verify-full
  max_connections: 20
  connection_timeout: 30
```

**`repository/configs/datasources/redis_features.yaml`**:
```yaml
name: redis_features
type: redis
config:
  host: ${REDIS_HOST}
  port: 6379
  password: ${REDIS_PASSWORD}
  db: 0
  key_prefix: "features:"
  ttl: 86400  # Default TTL in seconds (24 hours)
```

**`repository/configs/datasources/neo4j_graph.yaml`**:
```yaml
name: neo4j_graph
type: neo4j
config:
  uri: ${NEO4J_URI}  # e.g., bolt://localhost:7687
  user: ${NEO4J_USER}
  password: ${NEO4J_PASSWORD}
  database: ${NEO4J_DATABASE}  # e.g., neo4j
  max_connection_lifetime: 3600
  max_connection_pool_size: 50
  connection_timeout: 30
```

### Feature Definitions Referencing Data Sources

Features reference data sources by name through the `datasource` field:

```yaml
# Aggregation feature - queries event data from PostgreSQL
- name: cnt_userid_login_1h
  type: aggregation
  method: count
  datasource: postgresql_events  # References postgresql_events.yaml
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  window: 1h
  when: type == "login"               # Database field (no prefix)

# Lookup feature - retrieves pre-computed value from Redis
- name: user_risk_score_90d
  type: lookup
  datasource: redis_features      # References redis_features.yaml
  key: "user_risk_score_90d:{event.user_id}"
  fallback: 50

# State feature - computes z-score from historical data
- name: zscore_userid_txn_amt
  type: state
  method: z_score
  datasource: clickhouse_events    # References clickhouse_events.yaml
  dimension: user_id
  dimension_value: "{event.user_id}"
  field: amount
  current_value: "{event.amount}"
  window: 90d
  when: type == "transaction"         # Database field (no prefix)

# Graph feature - analyzes network relationships from Neo4j
- name: centrality_userid_device_30d
  type: graph
  method: graph_centrality
  datasource: neo4j_graph           # References neo4j_graph.yaml
  dimension: user_id
  dimension_value: "{event.user_id}"
  dimension2: device_id
  window: 30d

# Expression feature - no datasource needed
- name: rate_userid_login_failure
  type: expression
  method: expression
  expression: "failed_login_count_1h / login_count_1h"
  depends_on:
    - failed_login_count_1h
    - login_count_1h
  # Note: Expression features don't need datasource
```

### Implementation Pattern

```rust
// Data source configuration loaded from repository/configs/datasources/
pub struct DataSourceConfig {
    pub name: String,
    pub source_type: DataSourceType,
    pub config: serde_json::Value,
}

pub enum DataSourceType {
    ClickHouse,
    PostgreSQL,
    Redis,
    Neo4j,
}

// Feature type enum with Lookup as independent category
pub enum FeatureType {
    Aggregation { method: AggregationType, config: AggregationConfig },
    State { method: StateQueryType, config: StateConfig },
    Sequence { method: SequenceAnalysisType, config: SequenceConfig },
    Graph { method: GraphAnalysisType, config: GraphConfig },
    Expression { expr: String, depends_on: Vec<String> },
    Lookup { key: String, fallback: Option<Value> },  // New category
}

// Feature definition references datasource by name
pub struct FeatureDefinition {
    pub name: String,
    pub feature_type: FeatureType,
    pub datasource: Option<String>,  // References datasource name
    // ...
}

// Feature executor with datasource registry
pub struct FeatureExecutor {
    datasources: HashMap<String, Box<dyn DataSource>>,
}

impl FeatureExecutor {
    // Load datasources from repository/configs/datasources/
    pub fn new(datasource_configs: Vec<DataSourceConfig>) -> Result<Self> {
        let mut datasources = HashMap::new();
        for config in datasource_configs {
            let datasource = create_datasource(&config)?;
            datasources.insert(config.name.clone(), datasource);
        }
        Ok(Self { datasources })
    }

    pub fn execute(&self, feature: &FeatureDefinition) -> Result<Value> {
        match &feature.feature_type {
            // Lookup - simple key-value retrieval
            FeatureType::Lookup { key, fallback } => {
                let datasource = self.datasources.get(
                    feature.datasource.as_ref().ok_or("datasource required")?
                )?;
                datasource.get(key).or(fallback.clone())
            }

            // Aggregation - compute from events
            FeatureType::Aggregation { operator, config } => {
                let datasource = self.datasources.get(
                    feature.datasource.as_ref().ok_or("datasource required")?
                )?;
                AggregationExecutor::new(datasource).execute(operator, config)
            }

            // Expression - no datasource needed
            FeatureType::Expression { expr, depends_on } => {
                ExpressionEngine::evaluate(expr, depends_on, context)
            }

            // ... other types
        }
    }
}
```

### Feature Category Requirements

| Feature Type | Needs `datasource`? | Needs `operator`? | Description |
|--------------|---------------------|-------------------|-------------|
| **Aggregation** | âœ… Yes | âœ… Yes | Queries event data for real-time computation |
| **State** | âœ… Yes | âœ… Yes | Queries historical data for baseline analysis |
| **Sequence** | âœ… Yes | âœ… Yes | Queries time-series data for pattern analysis |
| **Graph** | âœ… Yes | âœ… Yes | Queries relationship data for graph algorithms |
| **Expression** | âŒ No | âœ… Yes | Only consumes other feature results |
| **Lookup** | âœ… Yes | âŒ No | Directly retrieves pre-computed values |

---

## Table of Contents

- [Data Source Configuration](#data-source-configuration)
- [1. Aggregation (æ•°ä¸œè¥¿)](#1-aggregation-æ•°ä¸œè¥¿)
- [2. State (çœ‹æœ€è¿‘çŠ¶æ€)](#2-state-çœ‹æœ€è¿‘çŠ¶æ€)
- [3. Sequence (çœ‹è¿‡ç¨‹)](#3-sequence-çœ‹è¿‡ç¨‹)
- [4. Graph (çœ‹å…³ç³»å›¾)](#4-graph-çœ‹å…³ç³»å›¾)
- [5. Expression (ç®—åˆ†æ•°)](#5-expression-ç®—åˆ†æ•°)
- [6. Lookup (æŸ¥é¢„ç®—å€¼)](#6-lookup-æŸ¥é¢„ç®—å€¼)
- [Implementation Roadmap](#implementation-roadmap)
- [By Risk Domain](#by-risk-domain)

---

## 1. Aggregation (æ•°ä¸œè¥¿)

**Purpose:** Count events, aggregate values, and compute statistical measures.

### Key Concepts

**Understanding `dimension` vs `field`:**

- **`dimension`** - èšåˆçš„**åˆ†ç»„ç»´åº¦**ï¼ˆGROUP BYï¼‰
  - è¡¨ç¤º"æŒ‰ä»€ä¹ˆæ¥åˆ†ç»„"
  - ä¾‹å¦‚: `dimension: user_id` è¡¨ç¤ºæŒ‰ç”¨æˆ·åˆ†ç»„
  - ç›¸å½“äºSQLä¸­çš„ `GROUP BY user_id`

- **`field`** - èšåˆçš„**è®¡ç®—å­—æ®µ**ï¼ˆèšåˆå‡½æ•°ä½œç”¨çš„å­—æ®µï¼‰
  - è¡¨ç¤º"å¯¹å“ªä¸ªå­—æ®µè¿›è¡Œè®¡ç®—"
  - ä¾‹å¦‚: `field: amount` è¡¨ç¤ºå¯¹é‡‘é¢å­—æ®µè¿›è¡Œèšåˆ
  - ç›¸å½“äºSQLä¸­çš„ `AVG(amount)`, `SUM(amount)` ç­‰

**ç¤ºä¾‹ç†è§£:**
```yaml
- name: avg_userid_order_amt_30d
  dimension: user_id    # æŒ‰ç”¨æˆ·åˆ†ç»„
  field: amount         # è®¡ç®—é‡‘é¢çš„å¹³å‡å€¼
```
ç›¸å½“äºSQL:
```sql
SELECT user_id, AVG(amount)
FROM events
WHERE type='order' AND timestamp > now() - 30d
GROUP BY user_id
```

**ä»€ä¹ˆæ—¶å€™éœ€è¦`field`:**
- `count` - âŒ ä¸éœ€è¦ï¼ˆåªè®¡æ•°ï¼Œä¸å…³å¿ƒå…·ä½“å­—æ®µå€¼ï¼‰
- `sum`, `avg`, `max`, `min`, `stddev` - âœ… éœ€è¦ï¼ˆå¿…é¡»æŒ‡å®šå¯¹å“ªä¸ªå­—æ®µè¿›è¡Œè®¡ç®—ï¼‰
- `distinct` - âœ… éœ€è¦ï¼ˆç»Ÿè®¡æŸå­—æ®µçš„ä¸åŒå€¼æ•°é‡ï¼‰

### `when` æ¡ä»¶ä¸­çš„å­—æ®µå¼•ç”¨è¯­æ³•

åœ¨ `when` æ¡ä»¶ä¸­è¿‡æ»¤æ•°æ®åº“è¡Œæ—¶ï¼Œå¯ä»¥å¼•ç”¨ä¸¤ç§ç±»å‹çš„å­—æ®µï¼š

**1. æ•°æ®åº“å­—æ®µï¼ˆæ¥è‡ª entity æŒ‡å®šçš„æ•°æ®è¡¨ï¼‰**
- ä¸éœ€è¦å‰ç¼€ï¼Œç›´æ¥å¼•ç”¨åˆ—å
- ç¤ºä¾‹ï¼š`type`, `status`, `amount`, `country`
- æ”¯æŒ JSON åµŒå¥—å­—æ®µï¼š`attributes.device.fingerprint`, `metadata.user.tier`

**2. è¯·æ±‚å­—æ®µï¼ˆæ¥è‡ª API è¯·æ±‚çš„ context.eventï¼‰**
- ä½¿ç”¨æ¨¡æ¿è¯­æ³•åŠ èŠ±æ‹¬å·ï¼š`{event.field_name}`
- ç¤ºä¾‹ï¼š`{event.user_id}`, `{event.min_amount}`, `{event.threshold}`
- ç”¨äºåŠ¨æ€è¿‡æ»¤å’Œæ¨¡æ¿æ›¿æ¢

**ç¤ºä¾‹ï¼š**

```yaml
# æ•°æ®åº“å­—æ®µè¿‡æ»¤ï¼ˆæ— éœ€å‰ç¼€ï¼‰
when: type == "transaction"

# æ•°æ®åº“ JSON åµŒå¥—å­—æ®µè®¿é—®
when: attributes.risk_level == "high"

# ç»„åˆæ•°æ®åº“å­—æ®µå’Œè¯·æ±‚å­—æ®µ
when:
  all:
    - type == "payment"                      # æ•°æ®åº“å­—æ®µ
    - amount > {event.threshold}             # è¯·æ±‚å­—æ®µï¼ˆåŠ¨æ€å€¼ï¼‰
    - metadata.country == "{event.country}"  # æ•°æ®åº“ JSON å­—æ®µåŒ¹é…è¯·æ±‚å€¼

# å¤æ‚çš„ JSON åµŒå¥—å­—æ®µ
when: user.profile.verification_status == "verified"
```

**SQL ç”Ÿæˆç¤ºä¾‹ï¼š**

é…ç½®ï¼š
```yaml
when:
  all:
    - type == "transaction"
    - amount > {event.min_amount}
    - attributes.device_type == "mobile"
```

ç”Ÿæˆçš„ SQLï¼š
```sql
SELECT COUNT(*)
FROM events
WHERE user_id = $1
  AND event_timestamp >= NOW() - INTERVAL '24 hours'
  AND type = 'transaction'                           -- æ•°æ®åº“å­—æ®µ
  AND amount > $2                                     -- è¯·æ±‚å€¼æ›¿æ¢
  AND attributes->>'device_type' = 'mobile'          -- JSON å­—æ®µè®¿é—®
```

### `dimension` vs `when` - ä¸èƒ½äº’ç›¸æ›¿ä»£

**é‡è¦æ¦‚å¿µåŒºåˆ†:**

| å­—æ®µ | ä½œç”¨ | SQLç­‰ä»· | ç›®çš„ |
|------|------|---------|------|
| `dimension` | åˆ†ç»„ç»´åº¦ | `GROUP BY` | å†³å®š"**ä¸ºè°**è®¡ç®—"ï¼ˆåˆ†ç»„ï¼‰ |
| `when` | è¿‡æ»¤æ¡ä»¶ | `WHERE` | å†³å®š"**è®¡ç®—ä»€ä¹ˆ**"ï¼ˆè¿‡æ»¤äº‹ä»¶ï¼‰ |
| `field` | è®¡ç®—å­—æ®µ | `SUM(field)` | å†³å®š"**è®¡ç®—å“ªä¸ªå­—æ®µ**" |

**ç¤ºä¾‹å¯¹æ¯”:**

```yaml
# æ­£ç¡®ï¼šä½¿ç”¨dimensionè¿›è¡Œåˆ†ç»„
- name: cnt_userid_login_24h
  dimension: user_id              # ä¸ºæ¯ä¸ªç”¨æˆ·åˆ†åˆ«è®¡ç®—
  when: type == "login"           # åªç»Ÿè®¡ç™»å½•äº‹ä»¶ï¼ˆæ•°æ®åº“å­—æ®µï¼Œæ— éœ€å‰ç¼€ï¼‰
```

SQLç­‰ä»·:
```sql
SELECT user_id, COUNT(*)
FROM events
WHERE type = 'login' AND timestamp > now() - 24h
GROUP BY user_id               -- dimensionçš„ä½œç”¨
-- ç»“æœï¼šæ¯ä¸ªç”¨æˆ·éƒ½æœ‰è‡ªå·±çš„ç™»å½•æ¬¡æ•°
```

**å¦‚æœå»æ‰dimensionä¼šæ€æ ·ï¼Ÿ**

```yaml
# é”™è¯¯ï¼šç¼ºå°‘dimensionï¼Œæ²¡æœ‰åˆ†ç»„
- name: cnt_all_login_24h
  when: type == "login"           # æ•°æ®åº“å­—æ®µï¼Œæ— éœ€å‰ç¼€
  # æ²¡æœ‰dimension = æ²¡æœ‰åˆ†ç»„
```

SQLç­‰ä»·:
```sql
SELECT COUNT(*)
FROM events
WHERE type = 'login' AND timestamp > now() - 24h
-- æ²¡æœ‰ GROUP BY
-- ç»“æœï¼šæ‰€æœ‰ç”¨æˆ·çš„ç™»å½•æ¬¡æ•°åŠ åœ¨ä¸€èµ·ï¼Œåªæœ‰ä¸€ä¸ªæ€»æ•°ï¼
```

**dimension å’Œ when çš„é…åˆä½¿ç”¨:**

```yaml
- name: cnt_userid_txn_24h_large
  dimension: user_id              # æŒ‰ç”¨æˆ·åˆ†ç»„
  when:
    all:
      - type == "transaction"        # è¿‡æ»¤ï¼šåªè¦äº¤æ˜“äº‹ä»¶ï¼ˆæ•°æ®åº“å­—æ®µï¼Œæ— éœ€å‰ç¼€ï¼‰
      - amount > 1000                # è¿‡æ»¤ï¼šé‡‘é¢å¤§äº1000ï¼ˆæ•°æ®åº“å­—æ®µï¼Œæ— éœ€å‰ç¼€ï¼‰
```

SQLç­‰ä»·:
```sql
SELECT user_id, COUNT(*)
FROM events
WHERE type = 'transaction'          -- whenæ¡ä»¶1ï¼ˆæ•°æ®åº“å­—æ®µï¼‰
  AND amount > 1000                 -- whenæ¡ä»¶2ï¼ˆæ•°æ®åº“å­—æ®µï¼‰
  AND timestamp > now() - 24h
GROUP BY user_id                    -- dimension
-- ç»“æœï¼šæ¯ä¸ªç”¨æˆ·çš„å¤§é¢äº¤æ˜“ï¼ˆ>1000ï¼‰æ¬¡æ•°
```

**æ€»ç»“:**
- âœ… `dimension` åˆ›å»ºåˆ†ç»„ï¼Œæ¯ç»„ä¸€ä¸ªç»“æœå€¼
- âœ… `when` è¿‡æ»¤äº‹ä»¶ï¼Œåªæœ‰ç¬¦åˆæ¡ä»¶çš„äº‹ä»¶å‚ä¸è®¡ç®—
- âŒ **ä¸èƒ½**ç”¨ `when` æ›¿ä»£ `dimension`ï¼Œå®ƒä»¬çš„ä½œç”¨å®Œå…¨ä¸åŒï¼

### ä¸ºä»€ä¹ˆ `dimension_value` ä¸èƒ½ç”¨ `when` æ›¿ä»£ï¼Ÿ

**å¸¸è§è¯¯è§£:** "æ—¢ç„¶ `dimension_value: "{event.user_id}"` ä¹Ÿæ˜¯ä»è¯·æ±‚äº‹ä»¶ä¸­å–å€¼ï¼Œä¸ºä»€ä¹ˆä¸èƒ½ç”¨ `when: user_id == ...` æ›¿ä»£ï¼Ÿ"

**å…³é”®åŒºåˆ«:**

| æ–¹å¼ | æ€§è´¨ | ç»“æœæ•°é‡ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|---------|
| `dimension + dimension_value` | **åŠ¨æ€åˆ†ç»„** | ä¸ºæ•°æ®ä¸­**æ¯ä¸ªä¸åŒçš„å€¼**éƒ½è®¡ç®—ä¸€ä¸ªç»“æœ | ä¸ºæ‰€æœ‰ç”¨æˆ·è®¡ç®— |
| `when` æ¡ä»¶ | **é™æ€è¿‡æ»¤** | åªèƒ½é’ˆå¯¹**ä¸€ä¸ªå†™æ­»çš„å€¼**è®¡ç®— | åªä¸ºç‰¹å®šç”¨æˆ·è®¡ç®— |

**ç¤ºä¾‹å¯¹æ¯”:**

```yaml
# æ–¹å¼1: ä½¿ç”¨ dimensionï¼ˆæ­£ç¡®ï¼‰ - åŠ¨æ€åˆ†ç»„
- name: cnt_userid_login_24h
  dimension: user_id
  dimension_value: "{event.user_id}"    # åŠ¨æ€æå–æ¯ä¸ªäº‹ä»¶çš„user_id
  when: type == "login"               # Database field (no prefix)
```

**æ‰§è¡Œé€»è¾‘:**
```
äº‹ä»¶æµ:
  event1: {user_id: "user_A", type: "login"}  â†’ å½’å…¥ user_A ç»„
  event2: {user_id: "user_B", type: "login"}  â†’ å½’å…¥ user_B ç»„
  event3: {user_id: "user_A", type: "login"}  â†’ å½’å…¥ user_A ç»„
  event4: {user_id: "user_C", type: "login"}  â†’ å½’å…¥ user_C ç»„

ç»“æœï¼ˆä¸ºæ¯ä¸ªç”¨æˆ·è®¡ç®—ï¼‰:
  user_A: 2æ¬¡
  user_B: 1æ¬¡
  user_C: 1æ¬¡
  ... ï¼ˆç³»ç»Ÿä¸­æ‰€æœ‰æœ‰ç™»å½•çš„ç”¨æˆ·ï¼‰
```

```yaml
# æ–¹å¼2: ç”¨ when æ¡ä»¶ï¼ˆé”™è¯¯ï¼‰ - é™æ€è¿‡æ»¤
- name: cnt_login_24h_for_userA
  when:
    all:
      - type == "login"              # æ•°æ®åº“å­—æ®µ
      - user_id == "user_A"          # å†™æ­»äº†åªçœ‹user_Aï¼
```

**æ‰§è¡Œé€»è¾‘:**
```
äº‹ä»¶æµ:
  event1: {user_id: "user_A", type: "login"}  â†’ âœ… è®¡å…¥
  event2: {user_id: "user_B", type: "login"}  â†’ âŒ è¿‡æ»¤æ‰
  event3: {user_id: "user_A", type: "login"}  â†’ âœ… è®¡å…¥
  event4: {user_id: "user_C", type: "login"}  â†’ âŒ è¿‡æ»¤æ‰

ç»“æœï¼ˆåªæœ‰ä¸€ä¸ªå€¼ï¼‰:
  æ€»è®¡: 2æ¬¡  ï¼ˆåªæœ‰user_Açš„ç™»å½•æ¬¡æ•°ï¼Œå…¶ä»–ç”¨æˆ·å…¨éƒ¨ä¸¢å¤±ï¼ï¼‰
```

**å®é™…è¿è¡Œæ—¶çš„åŒºåˆ«:**

å½“é£æ§å¼•æ“è¯„ä¼°ä¸€ä¸ªç”¨æˆ·ï¼ˆæ¯”å¦‚ user_Bï¼‰çš„äº¤æ˜“æ—¶ï¼š

```yaml
# ä½¿ç”¨ dimensionï¼ˆæ­£ç¡®ï¼‰
dimension: user_id
dimension_value: "{event.user_id}"  # è¿è¡Œæ—¶è‡ªåŠ¨æ›¿æ¢ä¸º "user_B"

â†’ æŸ¥è¯¢: SELECT COUNT(*) WHERE user_id = 'user_B' AND ...
â†’ è¿”å›: user_B çš„ç™»å½•æ¬¡æ•°
```

```yaml
# ä½¿ç”¨ whenï¼ˆé”™è¯¯ï¼‰
when: user_id == "user_A"           # å†™æ­»äº†ï¼

â†’ æŸ¥è¯¢: SELECT COUNT(*) WHERE user_id = 'user_A' AND ...
â†’ è¿”å›: user_A çš„ç™»å½•æ¬¡æ•°ï¼ˆé”™è¯¯ï¼æˆ‘ä»¬è¦çš„æ˜¯ user_B çš„æ•°æ®ï¼‰
```

**`dimension_value` çš„çœŸæ­£ä½œç”¨:**

`dimension_value` æ˜¯ä¸€ä¸ª**æ¨¡æ¿è¡¨è¾¾å¼**ï¼Œåœ¨è¿è¡Œæ—¶ä¼šè¢«æ›¿æ¢ï¼š
- é…ç½®æ—¶å†™: `dimension_value: "{event.user_id}"`
- è¿è¡Œæ—¶è¯„ä¼°å½“å‰äº‹ä»¶ï¼Œè‡ªåŠ¨å˜æˆ: `dimension_value: "user_123"` (å½“å‰ç”¨æˆ·)
- ç„¶åå»æŸ¥è¯¢è¿™ä¸ªç”¨æˆ·çš„å†å²æ•°æ®ï¼ŒæŒ‰ user_id åˆ†ç»„èšåˆ

**å…³é”®ç†è§£:**
- âœ… `dimension_value` æ˜¯**åˆ†ç»„ä¾æ®**ï¼Œå‘Šè¯‰ç³»ç»Ÿ"ä»å½“å‰äº‹ä»¶ä¸­æå–å“ªä¸ªå€¼ä½œä¸ºåˆ†ç»„key"
- âŒ `when` æ˜¯**å›ºå®šçš„è¿‡æ»¤æ¡ä»¶**ï¼Œåªèƒ½å†™æ­»ä¸€ä¸ªå…·ä½“å€¼ï¼Œæ— æ³•åŠ¨æ€é€‚åº”ä¸åŒç”¨æˆ·
- ğŸ’¡ ä½ éœ€è¦ä¸º**æ¯ä¸ªç”¨æˆ·**éƒ½è®¡ç®—ç‹¬ç«‹çš„ç»Ÿè®¡å€¼ï¼Œå¿…é¡»ç”¨ `dimension`ï¼Œä¸èƒ½ç”¨ `when`ï¼

### å®æ—¶é£æ§åœºæ™¯ä¸‹ `dimension` çš„çœŸæ­£ä½œç”¨

**ä½ çš„ç–‘é—®å¯èƒ½æ˜¯ï¼š** "åœ¨å®æ—¶å†³ç­–æ—¶ï¼Œåªé’ˆå¯¹å½“å‰ç”¨æˆ·è®¡ç®—ï¼Œä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ç”¨ `when` æ¡ä»¶è¿‡æ»¤ `user_id`ï¼Ÿ"

**ç­”æ¡ˆï¼šæŠ€æœ¯ä¸Šå¯ä»¥ï¼Œä½†è®¾è®¡ä¸Šä¸åº”è¯¥ã€‚** åŸå› å¦‚ä¸‹ï¼š

#### 1. **å®æ—¶è®¡ç®—æ—¶çš„å®é™…æŸ¥è¯¢**

å½“è¯„ä¼° user_B çš„äº¤æ˜“æ—¶ï¼Œå®é™…çš„ SQL æŸ¥è¯¢ï¼š

```sql
-- ä½¿ç”¨ dimension çš„æ–¹å¼
SELECT COUNT(*)
FROM events
WHERE user_id = 'user_B'      -- æ¥è‡ª dimension_value
  AND type = 'login'          -- æ¥è‡ª when æ¡ä»¶
  AND timestamp > now() - 24h
```

ä½ è¯´å¾—å¯¹ï¼åœ¨è¿™ä¸ªåœºæ™¯ä¸‹ï¼Œ`user_id = 'user_B'` ç¡®å®æ˜¯ä¸€ä¸ª WHERE æ¡ä»¶ï¼Œ**ç†è®ºä¸Šå¯ä»¥æ”¾åœ¨ `when` ä¸­**ã€‚

#### 2. **ä¸ºä»€ä¹ˆè¿˜è¦ç”¨ `dimension` è€Œä¸æ˜¯ `when`ï¼Ÿ**

**åŸå› ä¸€ï¼šè¯­ä¹‰æ¸…æ™°**

```yaml
# æ–¹å¼1: ä½¿ç”¨ dimensionï¼ˆæ¨èï¼‰ - è¯­ä¹‰æ˜ç¡®
dimension: user_id              # æ˜ç¡®ï¼šè¿™æ˜¯"ä¸ºè°"è®¡ç®—çš„ç»´åº¦
dimension_value: "{event.user_id}"
when: type == "login"           # æ˜ç¡®ï¼šè¿™æ˜¯è¿‡æ»¤æ¡ä»¶ï¼ˆæ•°æ®åº“å­—æ®µï¼Œæ— éœ€å‰ç¼€ï¼‰

# æ–¹å¼2: å…¨éƒ¨æ”¾åœ¨ whenï¼ˆä¸æ¨èï¼‰ - è¯­ä¹‰æ··ä¹±
when:
  all:
    - user_id == "{event.user_id}"     # è¿™ä¸æ˜¯è¿‡æ»¤ï¼Œæ˜¯æŒ‡å®šæŸ¥è¯¢ä¸»ä½“
    - type == "login"                  # è¿™æ‰æ˜¯è¿‡æ»¤ï¼ˆæ•°æ®åº“å­—æ®µï¼‰
```

**åŸå› äºŒï¼šæ”¯æŒå¤šç§è®¡ç®—æ¨¡å¼**

ç³»ç»Ÿéœ€è¦æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š

| æ¨¡å¼ | åœºæ™¯ | SQL | éœ€è¦ GROUP BYï¼Ÿ |
|------|------|-----|----------------|
| **åœ¨çº¿æ¨¡å¼** | å®æ—¶å†³ç­–å•ä¸ªäº‹ä»¶ | `WHERE user_id = :current_user` | âŒ ä¸éœ€è¦ |
| **ç¦»çº¿æ¨¡å¼** | æ‰¹é‡é¢„è®¡ç®—ç‰¹å¾ | `GROUP BY user_id` | âœ… éœ€è¦ |

ä½¿ç”¨ `dimension` çš„å¥½å¤„ï¼š**åŒä¸€ä¸ªé…ç½®å¯ä»¥ç”¨äºä¸¤ç§æ¨¡å¼**

```yaml
# åŒä¸€ä»½é…ç½®
dimension: user_id
dimension_value: "{event.user_id}"
when: type == "login"              # æ•°æ®åº“å­—æ®µï¼Œæ— éœ€å‰ç¼€

# åœ¨çº¿æ¨¡å¼æ‰§è¡Œæ—¶:
SELECT COUNT(*) WHERE user_id = 'user_B' AND type = 'login'

# ç¦»çº¿æ‰¹é‡è®¡ç®—æ—¶:
SELECT user_id, COUNT(*) WHERE type = 'login' GROUP BY user_id
```

**åŸå› ä¸‰ï¼šæŸ¥è¯¢ä¼˜åŒ–**

ç³»ç»Ÿå¯ä»¥è¯†åˆ« `dimension` æ˜¯åˆ†ç»„ç»´åº¦ï¼Œåšé’ˆå¯¹æ€§ä¼˜åŒ–ï¼š
- è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ç´¢å¼•
- è¯†åˆ«åˆ†åŒºé”®ï¼ˆå¦‚æœæ•°æ®åº“æŒ‰ user_id åˆ†åŒºï¼‰
- å¹¶è¡Œè®¡ç®—ä¼˜åŒ–

å¦‚æœå…¨éƒ¨æ”¾åœ¨ `when` ä¸­ï¼Œç³»ç»Ÿæ— æ³•åŒºåˆ†å“ªä¸ªæ¡ä»¶æ˜¯"åˆ†ç»„ç»´åº¦"ï¼Œå“ªä¸ªæ˜¯"è¿‡æ»¤æ¡ä»¶"ã€‚

**åŸå› å››ï¼šé…ç½®å¤ç”¨**

```yaml
# ä½¿ç”¨ dimension - å¯ä»¥è½»æ¾æ”¹å˜ç»´åº¦
dimension: user_id       # æŒ‰ç”¨æˆ·
# dimension: device_id   # æ”¹æˆæŒ‰è®¾å¤‡ï¼Œåªæ”¹ä¸€è¡Œ
# dimension: ip_address  # æ”¹æˆæŒ‰IPï¼Œåªæ”¹ä¸€è¡Œ

# ä½¿ç”¨ when - è¦æ”¹å¤šå¤„
when:
  all:
    - user_id == "{event.user_id}"        # è¦æ”¹è¿™é‡Œ
    - type == "login"                     # æ•°æ®åº“å­—æ®µ
```

#### æ€»ç»“ï¼šè®¾è®¡åŸåˆ™

| å­—æ®µ | è¯­ä¹‰ | ä½œç”¨ |
|------|------|------|
| `dimension` | "**ä¸ºè°**è®¡ç®—"ï¼ˆæŸ¥è¯¢ä¸»ä½“ï¼‰ | æŒ‡å®šèšåˆç»´åº¦ï¼Œæ”¯æŒåœ¨çº¿/ç¦»çº¿ä¸¤ç§æ¨¡å¼ |
| `when` | "**ä»€ä¹ˆæ ·çš„**äº‹ä»¶å‚ä¸è®¡ç®—"ï¼ˆä¸šåŠ¡è¿‡æ»¤ï¼‰ | è¿‡æ»¤ç¬¦åˆä¸šåŠ¡æ¡ä»¶çš„äº‹ä»¶ |

**è™½ç„¶åœ¨çº¯åœ¨çº¿åœºæ™¯ä¸‹ï¼ŒæŠ€æœ¯ä¸Šå¯ä»¥æŠŠ dimension_value æ”¾è¿› whenï¼Œä½†ä¸ºäº†ï¼š**
- âœ… è¯­ä¹‰æ¸…æ™°ï¼ˆæ˜ç¡®åŒºåˆ†"ä¸ºè°"å’Œ"ä»€ä¹ˆ"ï¼‰
- âœ… æ”¯æŒç¦»çº¿æ‰¹é‡è®¡ç®—
- âœ… ä¾¿äºç³»ç»Ÿä¼˜åŒ–
- âœ… é…ç½®æ›´å®¹æ˜“ç»´æŠ¤å’Œå¤ç”¨

**æˆ‘ä»¬ä»ç„¶å»ºè®®ä½¿ç”¨ `dimension` å­—æ®µã€‚**

### DSLä¸€è‡´æ€§åˆ†æ âœ…

**ç»“è®ºï¼šæ‰€æœ‰Aggregationæ“ä½œç¬¦çš„DSLç»“æ„é«˜åº¦ä¸€è‡´ï¼Œå¯ä»¥ç”¨ç»Ÿä¸€çš„Rustå‡½æ•°å®ç°ï¼**

| å­—æ®µ | count | sum | avg | max | min | distinct | stddev | ä¸€è‡´æ€§ |
|------|-------|-----|-----|-----|-----|----------|--------|--------|
| `type` | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… 100% |
| `operator` | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… 100% |
| `datasource` | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… 100% |
| `entity` | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… 100% |
| `dimension` | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… 100% |
| `dimension_value` | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… 100% |
| `window` | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… 100% |
| `when` | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… 100% |
| `field` | âŒ | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âš ï¸ ä»…countä¸éœ€è¦ |

**å®ç°å»ºè®®ï¼š**

```rust
// âœ… ç»Ÿä¸€çš„é…ç½®ç»“æ„
struct AggregationConfig {
    datasource: String,
    entity: String,
    dimension: String,
    dimension_value: String,
    field: Option<String>,      // countæ—¶ä¸ºNoneï¼Œå…¶ä»–ä¸ºSome(field_name)
    window: Duration,
    when: Option<Condition>,
}

// âœ… ç»Ÿä¸€çš„æ‰§è¡Œå™¨
impl AggregationExecutor {
    // ä¸€ä¸ªå‡½æ•°å¤„ç†æ‰€æœ‰operatorï¼
    fn execute(&self, op: AggregationType, config: &AggregationConfig) -> Result<Value> {
        // å”¯ä¸€çš„åŒºåˆ«æ˜¯ç”Ÿæˆçš„SQLèšåˆå‡½æ•°ä¸åŒï¼š
        // COUNT(*) vs SUM(field) vs AVG(field) vs MAX(field) ...
        let sql = self.build_query(op, config)?;
        self.datasource.query(&sql)
    }
}
```

**ä¼˜åŠ¿ï¼š**
- âœ… ä»£ç å¤ç”¨ç‡é«˜ï¼ˆå…±äº«æ—¶é—´çª—å£ã€ç»´åº¦åˆ†ç»„ã€æ¡ä»¶è¿‡æ»¤é€»è¾‘ï¼‰
- âœ… æ˜“äºæ‰©å±•ï¼ˆæ·»åŠ æ–°operatoråªéœ€åœ¨enumä¸­å¢åŠ variantï¼‰
- âœ… ç»Ÿä¸€æµ‹è¯•ï¼ˆä¸€å¥—æµ‹è¯•æ¡†æ¶è¦†ç›–æ‰€æœ‰operatorï¼‰
- âœ… é…ç½®ä¸€è‡´ï¼ˆç”¨æˆ·å­¦ä¹ ä¸€æ¬¡å°±èƒ½ä½¿ç”¨æ‰€æœ‰operatorï¼‰

### âœ… 1.1 Basic Counting
**Status:** Implemented

Count events and unique values within time windows.

**Operators:**
- `count` - Count events matching conditions
- `distinct` - Count unique values of a field (also used for entity linking)

**Use Cases:**
- Login attempts in time window
- Transaction count
- Failed payment attempts
- Unique IP addresses per user
- **Entity linking**: Devices associated with an IP (use `distinct`)
- **Entity linking**: Users per device (use `distinct`)

**Example:**
```yaml
- name: cnt_userid_login_24h
  type: aggregation
  method: count
  datasource: postgresql_events
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  window: 24h
  when: type == "login"               # Database field (no prefix)
```

---

### âœ… 1.2 Basic Aggregations
**Status:** Implemented

Statistical aggregations over numeric fields.

**Operators:**
- `sum` - Sum of field values
- `avg` - Average of field values
- `max` - Maximum value
- `min` - Minimum value

**Use Cases:**
- Total transaction amount
- Average order value
- Maximum single transaction
- Minimum deposit amount

**Example:**
```yaml
- name: sum_userid_txn_amt_24h
  type: aggregation
  method: sum
  datasource: postgresql_events
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  field: amount
  window: 24h
  when: type == "transaction"         # Database field (no prefix)
```

---

### ğŸ“‹ 1.3 Statistical Aggregations
**Status:** Planned - Medium Priority

Advanced statistical measures for distribution analysis.

**Proposed Operators:**
- `stddev` - Standard deviation
- `variance` - Variance
- `percentile` - Nth percentile value
- `median` - Median value
- `mode` - Most frequent value
- `entropy` - Shannon entropy (diversity measure)
- `coefficient_of_variation` - Stddev / mean

**Use Cases:**
- Transaction amount variability
- Behavior consistency scoring
- Distribution analysis
- User behavior diversity

**Proposed Syntax:**
```yaml
- name: stddev_userid_txn_amt_30d
  type: aggregation
  method: stddev
  datasource: postgresql_events
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  field: amount
  window: 30d
  when: type == "transaction"         # Database field (no prefix)
```

---

## 2. State (çœ‹æœ€è¿‘çŠ¶æ€)

**Purpose:** Statistical comparison and baseline analysis for anomaly detection.

> **Note:** State operators focus on **statistical comparisons** (z-score, baseline deviation, etc.). For simple lookups, use `datasource` configuration without operators. See "Data Source Configuration" section.

### ğŸ“‹ 2.1 Time-of-Day/Week State
**Status:** Planned - Medium Priority

Temporal pattern features based on time of day/week.

**Proposed Operators:**
- `timezone_consistency` - Timezone pattern consistency check

> **Note:** Simple time-based checks (e.g., off-hours activity) should use **Expression** or **Aggregation** operators, not State operators:
> - Off-hours check: Use expression like `event.hour < 8 || event.hour > 22`
> - Off-hours count: Use aggregation with when condition (see State operators section for examples)
>
> **Note:** Distribution-style features (e.g. hour-of-day or day-of-week histograms) are **not** State operators. They should be implemented as **Aggregation operators** over derived time dimensions (e.g. `hour_of_day`, `day_of_week` fields).

**Use Cases:**
- Timezone anomaly detection
- Behavioral consistency across timezones
- VPN/proxy detection

**Proposed Syntax:**
```yaml
- name: timezone_consistency_userid_7d
  type: state
  method: timezone_consistency
  datasource: clickhouse_events
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  window: 7d
  expected_timezone: "{user.timezone}"
```

---

### ğŸ“‹ 2.2 Historical Baseline State
**Status:** Planned - Low Priority

Compare current behavior to historical baselines.

**Proposed Operators:**
- `deviation_from_baseline` - Compare to historical average
- `percentile_rank` - Rank compared to history
- `z_score` - Statistical z-score
- `is_outlier` - Statistical outlier detection

**Use Cases:**
- Anomaly detection
- Behavior change detection
- Risk scoring
- Account takeover indicators

**Proposed Syntax:**
```yaml
- name: zscore_userid_txn_amt
  type: state
  method: z_score
  datasource: clickhouse_events
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  field: amount
  current_value: "{event.amount}"
  window: 90d
  when: type == "transaction"         # Database field (no prefix)
```

---

## 3. Sequence (çœ‹è¿‡ç¨‹)

**Purpose:** Analyze patterns, trends, and sequences of events over time.

### ğŸ“‹ 3.1 Pattern Sequences
**Status:** Planned - High Priority

Detect sequential patterns and consecutive events.

**Proposed Operators:**
- `consecutive_count` - Count consecutive occurrences
- `streak` - Longest streak of condition
- `sequence_match` - Match event sequences
- `pattern_frequency` - Frequency of specific patterns

**Use Cases:**
- Consecutive failed logins
- Consecutive successful transactions
- Login â†’ Transaction â†’ Withdrawal pattern
- Dormant account reactivation
- Unusual event sequences

**Proposed Syntax:**
```yaml
- name: consec_userid_login_1h_failed
  type: sequence
  method: consecutive_count
  datasource: clickhouse_events
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  window: 1h
  when:
    all:
      - type == "login"              # Database field (no prefix)
      - status == "failed"           # Database field (no prefix)
  order_by: timestamp
  reset_when: status == "success"    # Database field (no prefix)
```

---

### ğŸ“‹ 3.2 Trend Detection
**Status:** Planned - Medium Priority

Detect changes and trends over time.

**Proposed Operators:**
- `trend` - Calculate trend (increasing/decreasing/stable)
- `percent_change` - Percentage change between windows
- `rate_of_change` - Rate of change over time
- `anomaly_score` - Statistical anomaly detection
- `seasonal_deviation` - Deviation from seasonal baseline

**Use Cases:**
- Sudden transaction volume spike
- Spending pattern shift
- Behavior change detection
- Account takeover indicators

**Proposed Syntax:**
```yaml
- name: pctchg_userid_txn_amt_1h
  type: sequence
  method: percent_change
  datasource: clickhouse_events
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  field: amount
  window: 1h
  aggregation: sum
  when: type == "transaction"         # Database field (no prefix)
```

**Calculation:**
- Current window: [now - 1h, now]
- Baseline window: [now - 2h, now - 1h]
- Percent change: (current - baseline) / baseline Ã— 100%

---

### ğŸ’¡ 3.3 Session-Based Analysis
**Status:** Use Aggregation Operators

Session-based features should be implemented using **Aggregation operators** with `session_id` provided by the business system.

**Implementation Approach:**

| Session Metric | Implementation |
|----------------|----------------|
| Session count | `distinct(session_id)` |
| Average session duration | `avg(session_duration)` where business system provides duration |
| Events per session | `expression: total_events / distinct(session_id)` |
| Session gap | Compute via business system or use `time_since` on session_start_time |

**Example:**
```yaml
# Session count - using distinct
- name: distinct_userid_session_24h
  type: aggregation
  method: distinct
  datasource: postgresql_events
  dimension: user_id
  dimension_value: "{event.user_id}"
  field: session_id
  window: 24h

# Average session duration - using avg
- name: avg_userid_session_duration_7d
  type: aggregation
  method: avg
  datasource: postgresql_events
  dimension: user_id
  dimension_value: "{event.user_id}"
  field: session_duration  # Business system provides this
  window: 7d

# Events per session - using expression
- name: events_per_session_7d
  type: expression
  method: expression
  expression: "total_events_7d / distinct_sessions_7d"
  depends_on:
    - total_events_7d
    - distinct_sessions_7d
```

**Use Cases:**
- Bot detection (high session count, short duration)
- Automated script detection (abnormal events per session)
- Human behavior validation (session patterns)
- Session hijacking detection (sudden session characteristic changes)

> **Important**: Business system is responsible for computing `session_id` based on timeout rules (e.g., 30 minutes of inactivity = new session). This ensures consistent session definition across the platform.

---

### ğŸ“‹ 3.4 Time-Series Analysis
**Status:** Planned - Future

Advanced time-series analysis and forecasting.

**Proposed Operators:**
- `moving_average` - Moving average over window
- `lag` - Previous value at offset
- `forecast` - Time-series forecast
- `seasonality_score` - Seasonal pattern strength

**Use Cases:**
- Trend analysis
- Forecasting
- Smoothing
- Pattern detection
- Seasonal adjustments

**Proposed Syntax:**
```yaml
- name: movavg_userid_txn_amt_7d
  type: sequence
  method: moving_average
  datasource: clickhouse_events
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  field: amount
  window: 7d
  window_size: 7  # Number of periods for moving average
  aggregation: sum
```

---

### ğŸ“‹ 3.5 Complex Event Processing (CEP)
**Status:** Planned - Future

Stateful event pattern matching and correlation.

**Proposed Operators:**
- `event_pattern_match` - Match complex event patterns
- `state_machine` - Track state transitions
- `funnel_analysis` - Conversion funnel tracking
- `event_correlation` - Correlate related events

**Use Cases:**
- Fraud pattern detection
- User journey tracking
- Attack pattern recognition
- Complex rule evaluation
- Multi-stage fraud detection

**Proposed Syntax:**
```yaml
- name: pattern_userid_acct_takeover_1h
  type: sequence
  method: event_pattern_match
  datasource: clickhouse_events
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  window: 1h
  pattern:
    - event_type: password_reset
      min_count: 1
    - event_type: login
      min_count: 3
      when: status == "failed"            # Database field (no prefix)
    - event_type: login
      min_count: 1
      when: status == "success"           # Database field (no prefix)
    - event_type: transaction
      min_count: 1
  sequence: ordered  # ordered, unordered, partial
```

---

## 4. Graph (çœ‹å…³ç³»å›¾)

**Purpose:** Analyze connections, networks, and relationship patterns between entities using graph theory.

> **Note on Entity Linking:**
>
> Simple entity linking (e.g., "devices per IP", "users per device") should use **`distinct` aggregation**, not Graph operators:
>
> ```yaml
> # Count devices per IP - use distinct
> - name: distinct_ip_device_24h
>   type: aggregation
>   method: distinct
>   datasource: postgresql_events
>   entity: events
>   dimension: ip_address
>   dimension_value: "{event.ip_address}"
>   field: device_id
>   window: 24h
> ```
>
> Graph operators should focus on operations that **require graph algorithms** (network analysis, community detection, etc.).

### ğŸ“‹ 4.1 Network Analysis
**Status:** Planned - Low Priority (Complex)

Analyze entity relationships and network patterns using graph algorithms.

**Proposed Operators:**
- `graph_centrality` - Network centrality score
- `community_size` - Size of connected component
- `shared_entity_count` - Count shared connections
- `network_distance` - Distance between entities

**Use Cases:**
- Fraud ring detection
- Device sharing networks
- IP address clustering
- Account linking
- Synthetic identity detection
- Money mule networks

**Proposed Syntax:**
```yaml
- name: centrality_userid_device_30d
  type: graph
  method: graph_centrality
  datasource: neo4j_graph
  entity: events
  dimension: user_id
  dimension_value: "{event.user_id}"
  dimension2: device_id
  window: 30d
```

---

## 5. Expression (ç®—åˆ†æ•°)

**Purpose:** Compute custom scores, evaluate expressions, and integrate models.

> **âš ï¸ Architecture Constraint (Red Line):** Expression operators **must not** access raw data sources or define time windows; they **only consume results from other features**. This ensures clear separation of concerns and prevents architecture degradation.

### âœ… 5.1 Custom Expressions
**Status:** Implemented (Partial)

Evaluate custom expressions using other features.

**Operators:**
- `expression` - Evaluate custom expressions

**Use Cases:**
- Ratio calculations
- Composite scores
- Derived features
- Custom business logic

**Example:**
```yaml
- name: rate_userid_login_failure
  type: expression
  method: expression
  expression: "failed_login_count_1h / login_count_1h"
  depends_on:
    - failed_login_count_1h
    - login_count_1h
```

---

### ğŸ“‹ 5.2 Machine Learning Integration
**Status:** Planned - Future

Integration with ML models and embeddings.

**Proposed Operators:**
- `ml_model_score` - Call ML model for prediction
- `embedding_similarity` - Similarity using embeddings
- `clustering_label` - Assign to cluster
- `anomaly_detection_score` - ML-based anomaly score

**Use Cases:**
- ML model integration
- Advanced fraud detection
- User behavior modeling
- Risk scoring
- Recommendation features

**Proposed Syntax:**
```yaml
- name: mlscore_userid_fraud
  type: expression
  method: ml_model_score
  model: fraud_detection_v2
  inputs:
    - transaction_count_24h
    - transaction_sum_24h
    - unique_devices_7d
    - account_age_days
  output: fraud_probability
```

---

## 6. Lookup (æŸ¥é¢„ç®—å€¼)

**Purpose:** Retrieve pre-computed feature values from Redis cache.

> **âš ï¸ Architecture Principle:** Lookup features only retrieve pre-computed values; they do not perform any computation. All computation should happen in other feature categories or external batch jobs.

### âœ… 6.1 Direct Lookups
**Status:** Implemented

Retrieve pre-computed values from Redis by key.

**Configuration Fields:**
- `type: lookup` - Feature category
- `datasource` - Data source name (references `repository/configs/datasources/`)
- `key` - Key template for retrieval (supports variable interpolation)
- `fallback` - Optional default value if key not found

**Use Cases:**
- Pre-computed risk scores (from batch jobs)
- User segments (from analytics pipeline)
- Cached aggregations (from scheduled computations)
- Device fingerprints and reputation scores

**Example:**
```yaml
- name: user_risk_score_90d
  type: lookup
  datasource: redis_features
  key: "user_risk_score:{event.user_id}"
  fallback: 50

- name: user_segment_label
  type: lookup
  datasource: redis_features
  key: "user_segment:{event.user_id}"
  fallback: "unknown"

- name: device_reputation_score
  type: lookup
  datasource: redis_features
  key: "device_reputation:{event.device_id}"
  fallback: 0
```

### Implementation Details

**Redis Configuration:**
- Fast in-memory cache (sub-millisecond latency)
- Key-based retrieval with pattern matching
- TTL support for automatic expiration
- Fallback values for missing keys
- Connection pooling for high concurrency

**Why Lookup is a Separate Category:**

âœ… **Semantic Clarity**: Explicitly indicates "no computation, just retrieval"
âœ… **Configuration Simplicity**: No operator needed, simpler YAML
âœ… **Performance Optimization**: Can use different caching strategies
âœ… **Schema Validation**: Clear requirements (needs datasource, no operator)

---

## Implementation Roadmap

### Phase 1: Core Enhancements (Q1 2025)
**Focus:** Complete basic operators and add high-priority features

- âœ… Complete Expression operator implementation
- ğŸ“‹ Implement Pattern sequences (3.1)
- ğŸ“‹ Add more time window units (weeks, months)

### Phase 2: Advanced Analytics (Q2 2025)
**Focus:** Statistical and behavioral analysis

- ğŸ“‹ Statistical aggregations (1.3)
- ğŸ“‹ Trend detection (3.2)
- ğŸ“‹ Time-of-day/week state (2.1)
- ğŸ’¡ Session-based analysis (3.3) - Use Aggregation operators

### Phase 3: Complex Features (Q3 2025)
**Focus:** Advanced graph analysis and baselines

- ğŸ“‹ Historical baseline state (2.2)
- ğŸ“‹ Network analysis (4.1) - basic
- ğŸ“‹ Time-series analysis (3.4) - basic

### Phase 4: Advanced/ML Integration (Q4 2025+)
**Focus:** AI and complex event processing

- ğŸ“‹ Machine learning integration (5.2)
- ğŸ“‹ Advanced network analysis algorithms (4.1)
- ğŸ“‹ Complex event processing (3.5)
- ğŸ“‹ Real-time streaming features

---

## By Risk Domain

| Risk Domain | Primary Categories | Key Operators |
|-------------|-------------------|---------------|
| **Account Security** | Aggregation, Sequence, Expression | count, consecutive_count, distinct(city), expression |
| **Transaction Fraud** | Aggregation, Sequence, Expression | sum, avg, stddev, trend, z_score, expression |
| **Bot Detection** | Aggregation, Sequence, Expression | distinct(session_id), avg(session_duration), expression, count |
| **Account Takeover** | State, Sequence, Aggregation | consecutive_count, deviation_from_baseline, z_score, distinct(city) |
| **Payment Fraud** | Aggregation, Sequence, Expression | count, sum, pattern_frequency, expression |
| **Synthetic Identity** | Graph, Aggregation | centrality, shared_entity_count, distinct |
| **Credit Risk** | Aggregation, State, Sequence | sum, avg, stddev, trend, baseline_deviation |
| **AML/Compliance** | Aggregation, Graph, Sequence | sum, distinct, centrality, pattern_match |

---

## Feature Category Summary

### By Implementation Status

| Category | Sub-Category | Status | Priority | Complexity |
|----------|--------------|--------|----------|------------|
| **Aggregation** | Basic Counting (1.1) | âœ… Implemented | - | Low |
| | Basic Aggregations (1.2) | âœ… Implemented | - | Low |
| | Statistical Aggregations (1.3) | ğŸ“‹ Planned | Medium | Medium |
| **State** | Time-of-Day/Week (2.1) | ğŸ“‹ Planned | Medium | Low |
| | Historical Baseline (2.2) | ğŸ“‹ Planned | Low | Medium |
| **Sequence** | Pattern Sequences (3.1) | ğŸ“‹ Planned | High | Medium |
| | Trend Detection (3.2) | ğŸ“‹ Planned | Medium | Medium |
| | Session-Based Analysis (3.3) | ğŸ’¡ Use Aggregation | - | - |
| | Time-Series Analysis (3.4) | ğŸ“‹ Planned | Future | High |
| | Complex Event Processing (3.5) | ğŸ“‹ Planned | Future | Very High |
| **Graph** | Network Analysis (4.1) | ğŸ“‹ Planned | Low | High |
| **Expression** | Custom Expressions (5.1) | âœ… Partial | - | Medium |
| | Machine Learning (5.2) | ğŸ“‹ Planned | Future | High |
| **Lookup** | Direct Lookups (6.1) | âœ… Implemented | - | Low |

---

## Feature Naming Convention

Feature names should follow a structured pattern for clarity and machine parseability.

### Naming Pattern

**For features with operators** (Aggregation, State, Sequence, Graph, Expression):
```
<operator>_<dimension>_<event>[_field]_<window>[_modifier]
```

**For Lookup features** (no operator):
```
<descriptive_name>
```

**Components (in order):**

1. **Operator** (required for computed features) - Operation type
   - Aggregation: `cnt`, `sum`, `avg`, `max`, `min`, `distinct`, `stddev`, `variance`, `percentile`, `median`, `mode`, `entropy`
   - State: `zscore`, `deviation`, `percentile`, `outlier`, `timezone`
   - Sequence: `consec`, `trend`, `pctchg`, `streak`
   - Graph: `centrality`, `community`, `shared`
   - Expression: `rate`, `ratio`, `score`

2. **Dimension** (required) - Aggregation dimension
   - `userid`, `deviceid`, `ip`, `acctid`, `sessid`, `email`

3. **Event** (required) - Event or entity type
   - `login`, `txn`, `pay`, `reg`, `checkout`, `pwd_reset`

4. **Field** (optional) - Field name for aggregations
   - `amt`, `val`, `score`, `dur`, `cnt`

5. **Window** (required for time-based) - Time window
   - `1h`, `24h`, `7d`, `30d`, `90d`

6. **Modifier** (optional) - Additional qualifier
   - `failed`, `success`, `new`, `change`

### Standard Abbreviations

To keep feature names concise, use these standard abbreviations:

| Full Word | Abbreviation | Usage |
|-----------|--------------|-------|
| **Events** |
| transaction | `txn` | `cnt_userid_txn_24h` |
| payment | `pay` | `sum_userid_pay_amt_7d` |
| register | `reg` | N/A (use event.account_age_days) |
| session | `sess` | `avg_userid_sess_dur_7d` |
| password | `pwd` | `consec_userid_pwd_reset_1h` |
| checkout | `checkout` | `cnt_userid_checkout_24h` |
| **Dimensions** |
| account | `acct` | `cnt_acctid_login_24h` |
| device | `dev` | Optional: `deviceid` or `devid` |
| session | `sess` | `cnt_sessid_event_1h` |
| **Fields** |
| amount | `amt` | `sum_userid_txn_amt_30d` |
| value | `val` | `max_userid_pay_val_1h` |
| count | `cnt` | Used in operator position |
| duration | `dur` | `avg_userid_sess_dur_7d` |
| distance | `dist` | `centrality_userid_device_30d` |
| **Operators** (already short) |
| count | `cnt` | `cnt_*` |
| average | `avg` | `avg_*` |
| distinct | `distinct` | `distinct_*` |
| consecutive | `consec` | `consec_*` |
| percent | `pct` | `pctchg_*` |
| **Modifiers** |
| failed | `failed` | `*_failed` |
| success | `success` | `*_success` |

**Guidelines:**
- **Abbreviations are ONLY used in the `name` field** - all other fields use full words
- Use abbreviations for words longer than 6 characters
- Keep common short words unchanged: `login`, `ip`, `sum`, `max`, `min`
- Be consistent: always use the same abbreviation for the same word

**Important:** Configuration fields use full words, not abbreviations:
```yaml
# âœ… Correct - abbreviation only in name
- name: sum_userid_txn_amt_24h     # name ä½¿ç”¨ç¼©å†™
  field: amount                    # field ä½¿ç”¨å®Œæ•´è¯
  when: type == "transaction"      # when ä½¿ç”¨å®Œæ•´è¯ï¼ˆæ•°æ®åº“å­—æ®µï¼Œæ— éœ€å‰ç¼€ï¼‰

# âŒ Wrong - don't use abbreviations in config
- name: sum_userid_txn_amt_24h
  field: amt                       # âŒ é”™è¯¯ï¼ˆä¸è¦ä½¿ç”¨ç¼©å†™ï¼‰
  when: type == "txn"              # âŒ é”™è¯¯ï¼ˆä¸è¦ä½¿ç”¨ç¼©å†™ï¼‰
```

### Examples

**Aggregation Features:**

```yaml
# Basic counting
cnt_userid_login_24h               # ç”¨æˆ·24å°æ—¶ç™»å½•æ¬¡æ•°
cnt_userid_txn_7d                  # ç”¨æˆ·7å¤©äº¤æ˜“æ¬¡æ•°
cnt_deviceid_login_1h              # è®¾å¤‡1å°æ—¶ç™»å½•æ¬¡æ•°

# Sum/Avg with field
sum_userid_txn_amt_30d             # ç”¨æˆ·30å¤©äº¤æ˜“é‡‘é¢æ€»å’Œ
avg_userid_pay_amt_7d              # ç”¨æˆ·7å¤©æ”¯ä»˜å¹³å‡é‡‘é¢
max_userid_txn_amt_24h             # ç”¨æˆ·24å°æ—¶æœ€å¤§äº¤æ˜“é‡‘é¢

# Distinct counting
distinct_userid_device_7d          # ç”¨æˆ·7å¤©å†…ä¸åŒè®¾å¤‡æ•°
distinct_userid_ip_24h             # ç”¨æˆ·24å°æ—¶å†…ä¸åŒIPæ•°
distinct_ip_userid_1h              # IP 1å°æ—¶å†…ä¸åŒç”¨æˆ·æ•°

# With modifier for conditions
cnt_userid_login_1h_failed         # ç”¨æˆ·1å°æ—¶å¤±è´¥ç™»å½•æ¬¡æ•°
cnt_userid_pay_24h_success         # ç”¨æˆ·24å°æ—¶æˆåŠŸæ”¯ä»˜æ¬¡æ•°
```

**State Features:**

```yaml
# Statistical comparison (planned)
zscore_userid_txn_amt              # ç”¨æˆ·äº¤æ˜“é‡‘é¢Z-score
deviation_userid_login_freq        # ç”¨æˆ·ç™»å½•é¢‘ç‡åç¦»åº¦
percentile_userid_txn_amt          # ç”¨æˆ·äº¤æ˜“é‡‘é¢ç™¾åˆ†ä½
timezone_userid_login_7d           # ç”¨æˆ·æ—¶åŒºä¸€è‡´æ€§æ£€æµ‹

# Note: Use Lookup features for pre-computed values:
- name: user_risk_score_90d
  type: lookup
  datasource: redis_features
  key: "user_risk_score:{event.user_id}"
  fallback: 50

# Time-based checks should use Expression or Aggregation:
# - Off-hours check: is_off_hours (expression: "event.hour < 8 || event.hour > 22")
# - Off-hours count: cnt_userid_login_7d_offhours (aggregation with when condition)

# Context data should be provided by business system:
# - event.account_age_days, user.last_login_at (temporal)
# - user.kyc_status, user.account_type, user.country (profile)
```

**Sequence Features:**

```yaml
# Pattern sequences
consec_userid_login_1h_failed      # ç”¨æˆ·1å°æ—¶è¿ç»­å¤±è´¥ç™»å½•æ¬¡æ•°
streak_userid_txn_7d               # ç”¨æˆ·7å¤©äº¤æ˜“è¿ç»­æ€§

# Trend detection
pctchg_userid_txn_amt              # ç”¨æˆ·äº¤æ˜“é‡‘é¢å˜åŒ–ç™¾åˆ†æ¯”
trend_userid_login_7d              # ç”¨æˆ·7å¤©ç™»å½•è¶‹åŠ¿

# Session analysis
avg_userid_sess_dur_7d             # ç”¨æˆ·7å¤©å¹³å‡ä¼šè¯æ—¶é•¿
```

**Graph Features:**

```yaml
# Entity linking - use distinct (not Graph operators)
distinct_ip_device_24h             # IP 24å°æ—¶å…³è”è®¾å¤‡æ•°ï¼ˆç”¨ distinctï¼‰
distinct_deviceid_userid_7d        # è®¾å¤‡7å¤©å…³è”ç”¨æˆ·æ•°ï¼ˆç”¨ distinctï¼‰

# Network analysis (planned)
centrality_userid_device_30d       # ç”¨æˆ·30å¤©è®¾å¤‡ç½‘ç»œä¸­å¿ƒåº¦
community_userid_network_30d       # ç”¨æˆ·30å¤©æ‰€åœ¨ç¤¾åŒºå¤§å°
shared_userid_device_30d           # ç”¨æˆ·é—´å…±äº«è®¾å¤‡æ•°
```

**Expression Features:**

```yaml
# Computed scores
score_userid_fraud                     # ç”¨æˆ·æ¬ºè¯ˆè¯„åˆ†
score_userid_risk                      # ç”¨æˆ·é£é™©è¯„åˆ†

# Ratio/Rate (complex expressions)
rate_userid_login_1h_failure           # ç”¨æˆ·1å°æ—¶ç™»å½•å¤±è´¥ç‡
ratio_userid_txn_7d_change             # ç”¨æˆ·7å¤©äº¤æ˜“æ¯”ç‡å˜åŒ–
```

**Lookup Features:**

```yaml
# Pre-computed values (no operator, descriptive names)
user_risk_score_90d                    # ç”¨æˆ·90å¤©é£é™©è¯„åˆ†ï¼ˆé¢„è®¡ç®—ï¼‰
user_segment                           # ç”¨æˆ·ç»†åˆ†æ ‡ç­¾
device_reputation_score                # è®¾å¤‡ä¿¡èª‰è¯„åˆ†
ip_risk_level                          # IPé£é™©ç­‰çº§

# Note: Lookup features don't follow the operator pattern
# Use descriptive names that indicate what is being looked up
```

**Avoid:**

```yaml
# âŒ Wrong order
userid_cnt_login_24h                   # Operator should be first
24h_login_cnt_userid                   # Wrong order

# âŒ Inconsistent abbreviations
count_userid_login_24h                 # Use 'cnt' not 'count'
cnt_user_id_login_24h                  # Use 'userid' not 'user_id'

# âŒ Too vague
cnt_24h                                # Missing dimension and event
zscore_1h                              # Missing dimension and event

# âŒ Adding type prefix (not needed)
agg_cnt_userid_login_24h               # Don't add 'agg_' prefix
zscore_userid_txn_amt            # Don't add 'state_' prefix
```

---

## Time Window Units

Corint uses concise time unit notation:

| Unit | Meaning | Type | Example |
|------|---------|------|---------|
| `s` | second | Physical | `login_count_30s` |
| `m` | minute | Physical | `login_count_5m` |
| `h` | hour | Physical | `login_count_1h`, `transaction_sum_24h` |
| `d` | day (24h) | Physical | `unique_devices_7d`, `transaction_sum_30d` |
| `mo` | month (calendar) | Business | `avg_txn_3mo` |
| `q` | quarter (calendar) | Business | `revenue_sum_1q` |
| `y` | year (calendar) | Business | `annual_txn_1y` |

---

## Design Principles

### 1. Category-Based Design
Each feature belongs to one primary category based on its purpose:
- **Aggregation** for counting and statistical calculations
- **State** for current/recent status checks
- **Sequence** for temporal patterns and trends
- **Graph** for entity connections and network analysis
- **Expression** for computed scores

### 2. Composability
Features from different categories can be combined:
- Aggregation results feed into Expression
- State checks can trigger Sequence analysis
- Graph features enhance Aggregation context

### 3. Performance
All operators should support:
- Time-windowed queries
- Efficient caching
- Incremental computation where possible
- Batch processing for bulk evaluation

### 4. Flexibility
- Parameterized dimensions
- Dynamic conditions (when clauses)
- Multiple data sources
- Template-based values

### 5. Observability
- Feature computation metrics
- Cache hit rates
- Query performance tracking
- Data quality monitoring

---

## Contributing

When adding new operators:

1. **Identify the category** - Which of the 5 categories does it belong to?
2. **Define the use case** - What risk scenarios does it address?
3. **Design the operator** - What parameters are needed?
4. **Implement efficiently** - Consider performance and scale
5. **Add tests** - Unit tests and integration tests
6. **Document examples** - Provide real-world examples
7. **Update this document** - Keep the feature catalog current

---

## References

- [Operator Implementation](crates/corint-runtime/src/feature/operator.rs)
- [Feature Definitions](repository/configs/features/)
- [Data Source Integration](crates/corint-runtime/src/datasource/)
- [Risk Rule Examples](repository/library/rules/)
