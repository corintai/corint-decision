# CORINT Risk Definition Language (RDL)
## Pipeline Specification (v0.2)

A **Pipeline** defines the full risk‚Äëprocessing flow in CORINT's Cognitive Risk Intelligence framework.
It represents a declarative Directed Acyclic Graph (DAG) composed of processing steps with explicit routing.

Pipelines orchestrate how events move through feature extraction, rule execution, and external service integration.

> **‚ö†Ô∏è Important:** This document clearly marks **‚úÖ Implemented** vs **üìã Planned** features.

**Current Implementation:**
- **Rules** detect and score individual risk patterns (‚úÖ Implemented)
- **Rulesets** produce **signals** (`approve`, `decline`, `review`, `hold`, `pass`) based on rule results (‚úÖ Implemented)
- **Pipelines** execute rulesets and route events through processing steps (‚úÖ Implemented)
- **Pipeline-level decision logic** can map ruleset signals to final results (‚úÖ Implemented)

---

## 1. Pipeline Structure

### 1.1 Implemented Fields (‚úÖ)

```yaml
pipeline:
  id: string                    # ‚úÖ Required: Unique identifier
  name: string                  # ‚úÖ Required: Human-readable name
  description: string           # ‚úÖ Optional: Description
  entry: string                 # ‚úÖ Required: ID of the first step to execute (DAG entry point)
  when:                         # ‚úÖ Optional: Execution condition
    all: [...]                  # Conditions using expression syntax
  steps:                        # ‚úÖ Required: Processing steps (see section 2)
    - step:
        id: string
        name: string
        type: string
        # ... type-specific fields
  metadata:                     # ‚úÖ Optional: Arbitrary key-value pairs
    <key>: <value>
```

### 1.2 Optional Decision Field (‚úÖ Implemented)

```yaml
pipeline:
  decision:                     # ‚úÖ Optional: Pipeline-level decision logic
    - when: <condition>         # Maps ruleset signals to final results
      result: <result>          # Final decision: approve/decline/review/hold
      actions: [...]            # Optional actions to execute
      reason: <reason>          # Optional reason
      terminate: true           # Optional: stop evaluating further rules
```

**Important:**
- The `entry` field is **required** and specifies which step to start with
- The `decision` field is **optional** and allows pipelines to map ruleset signals to final results
- Rulesets produce signals via `conclusion`, pipelines can then map these to results via `decision`

### 1.3 Execution Flow

Pipeline execution follows this flow:

```
whenÊù°‰ª∂Ê£ÄÊü• ‚Üí entry step ‚Üí next routing ‚Üí ... ‚Üí decisionÊúÄÁªàÂÜ≥Á≠ñ
```

**Step Routing Rules:**
- `entry: <step_id>` - Defines which step to start with
- `next: <step_id>` - Explicitly routes to the specified step
- `next: end` or **no `next`** - Ends step execution, flows to `decision`

**Key Points:**
- Pipeline is a **DAG (Directed Acyclic Graph)** - routing must be explicit
- Sequential execution requires explicit `next` declarations between steps
- Omitting `next` means "end here" - enables early termination from any step
- `decision` section is the terminal phase for making final actions

### 1.4 Pipeline Metadata (‚úÖ Implemented)

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `id` | string | Yes | Unique identifier for the pipeline |
| `name` | string | Yes | Human-readable name |
| `description` | string | No | Detailed description of pipeline purpose |
| `entry` | string | Yes | ID of the first step to execute |
| `when` | object | No | Execution condition (event type filter) |
| `steps` | array | Yes | List of processing steps |
| `metadata` | object | No | Arbitrary key-value pairs for documentation, versioning, authorship, etc. |

The `metadata` field allows you to attach arbitrary information to your pipeline for documentation, versioning, and management purposes.

**Note:** Unlike what was previously documented, there are **no required fields** within metadata. All metadata fields are optional and user-defined.

**Example**:
```yaml
pipeline:
  id: fraud_detection
  name: Fraud Detection Pipeline
  entry: initial_check
  description: Comprehensive fraud detection
  metadata:
    # All fields are optional - define what you need
    version: "2.1.0"
    author: "Risk Engineering Team"
    updated: "2025-12-20 14:30:00"
    owner: "fraud_team"
    environment: "production"
    tags: [fraud, risk_assessment]
```

### 1.5 When Condition (‚úÖ Implemented)

The `when` block controls whether the pipeline executes. Uses the same syntax as rule conditions.

```yaml
pipeline:
  when:
    all:
      - event.type == "payment"  # Only execute for payment events
      - event.amount > 100       # Additional condition (must use event. prefix)
```

If `when` condition is not met:
- Pipeline is skipped entirely
- No steps are executed
- Processing continues with next pipeline/rule

Each element is one of the pipeline constructs described below.

---

## 2. Step Types

A **step** is the smallest processing unit in a pipeline. All steps are wrapped in a `step:` object.

```yaml
- step:
    id: string                  # Required: Unique step identifier
    name: string                # Required: Human-readable name
    type: string                # Required: Step type (see below)
    when: <optional-condition>  # Optional: Condition for execution
    next: <step-id>             # Optional: Next step to execute
    # ... type-specific fields
```

### 2.1 Implemented Step Types (‚úÖ)

| type | Description | Status |
|------|-------------|--------|
| `router` | Pure routing step with conditional routes | ‚úÖ Implemented |
| `function` | Pure computation step | ‚úÖ Implemented |
| `rule` | Execute a single rule | ‚úÖ Implemented |
| `ruleset` | Execute a ruleset | ‚úÖ Implemented |
| `pipeline` | Call a sub-pipeline | ‚úÖ Implemented |
| `service` | Internal service call (database, cache, microservice, etc.) | ‚úÖ Implemented |
| `api` | External API lookup (supports single, any, all modes) | ‚úÖ Implemented |
| `trigger` | External action (message queue, webhook, notification) | ‚úÖ Implemented |
| `extract` | Feature extraction (legacy format) | ‚úÖ Implemented (legacy) |
| `reason` | LLM cognitive reasoning step (legacy format) | ‚úÖ Implemented (legacy) |

### 2.2 Planned Step Types (üìã)

| type | Description | Status |
|------|-------------|--------|
| `score` | Score computation or normalization | üìã Planned (use expression features instead) |
| `action` | Produces final decision outcome | üìã Planned (use ruleset conclusion instead) |
| `branch` | Conditional branching | üìã Planned (use router step instead) |
| `parallel` | Parallel execution | üìã Planned (currently in legacy format only) |
| `aggregate` | Aggregation of results | üìã Planned |

### 2.3 Step Conditions (‚úÖ Implemented)

Every step may include a conditional execution block:

```yaml
- step:
    id: high_value_check
    name: High Value Transaction Check
    type: ruleset
    ruleset: high_value_rules
    when:
      all:
        - event.amount > 1000
```

The step executes **only** if the `when` condition evaluates to true.

---

## 2.4 Complete Pipeline Example (‚úÖ Implemented Syntax)

```yaml
version: "0.1"

pipeline:
  id: payment_risk_pipeline
  name: Payment Risk Control Pipeline
  description: Comprehensive payment risk assessment with routing
  entry: ip_check               # Start with IP check step

  # Condition: Only execute for payment events
  when:
    all:
      - event.type == "payment"

  steps:
    - step:
        id: ip_check
        name: IP Address Check
        type: api
        api: ipinfo
        endpoint: ip_lookup
        params:
          ip: event.ip_address
        next: risk_assessment

    - step:
        id: risk_assessment
        name: Risk Assessment
        type: ruleset
        ruleset: payment_risk_rules
```

---

## 3. Branching (üìã Legacy Format Only)

> **‚ö†Ô∏è Note:** Branch syntax shown below is in **legacy format only**. For new pipelines, use **Router steps** with conditional routes instead.

A branch selects between multiple sub‚Äëpipelines based on conditions (legacy format):

```yaml
# LEGACY FORMAT - use router step instead for new pipelines
- branch:
    when:
      - condition: "event.type == 'login'"
        pipeline:
          - extract_login
          - login_rules

      - condition: "event.type == 'payment'"
        pipeline:
          - extract_payment
          - payment_rules
```

**Modern Alternative (‚úÖ Implemented):**

Use router steps with conditional routes:

```yaml
- step:
    id: event_router
    name: Event Type Router
    type: router
    routes:
      - next: login_flow
        when:
          all:
            - event.type == "login"
      - next: payment_flow
        when:
          all:
            - event.type == "payment"
    default: default_flow
```

---

## 4. Parallel Execution (üìã Legacy Format Only)

> **‚ö†Ô∏è Note:** Parallel execution is **not implemented** in the new PipelineStep format. It exists only in the legacy Step enum.

```yaml
# LEGACY FORMAT ONLY - not supported in new format
- parallel:
    - device_fingerprint
    - ip_reputation
    - llm_reasoning
  merge:
    method: all
```

**Current Workaround:**
Execute steps sequentially or use external orchestration.

---

## 5. Aggregation (üìã Not Implemented)

> **‚ö†Ô∏è Note:** Aggregation steps are **not implemented** in the current version.

```yaml
# NOT IMPLEMENTED
- aggregate:
    method: weighted
    weights:
      rules_engine: 0.5
      llm_reasoning: 0.3
      chainalysis: 0.2
```

**Current Workaround:**
Use expression features to compute weighted scores, or aggregate in ruleset conclusion logic.  

---

## 6. Imports and Include (Reusable Modules)

Pipelines use the `imports` section to declare dependencies on rulesets and other pipelines. This enables modular, reusable pipeline design.

### 6.1 Import Declaration

Pipelines use multi-document YAML format with `---` separator:

```yaml
version: "0.1"

# First document: Imports
imports:
  rulesets:
    - library/rulesets/fraud_detection_core.yaml
    - library/rulesets/payment_high_value.yaml
  pipelines:
    - library/pipelines/common_feature_extraction.yaml

---

# Second document: Pipeline definition
pipeline:
  id: fraud_detection_pipeline
  name: Fraud Detection Pipeline

  steps:
    - include:
        ruleset: fraud_detection_core
```

**Key Benefits:**
- **Explicit Dependencies** - All dependencies declared upfront
- **Compile-Time Resolution** - Dependencies resolved during compilation
- **Automatic Transitive Dependencies** - Importing a ruleset automatically loads all its rules
- **Zero Runtime Overhead** - All merging happens at compile time

### 6.2 Dependency Propagation

When a pipeline imports a ruleset, it automatically gets all the ruleset's rule dependencies:

```yaml
# Pipeline only needs to declare the ruleset
imports:
  rulesets:
    - library/rulesets/fraud_detection_core.yaml  # This ruleset imports 6 rules

---

pipeline:
  steps:
    - include:
        ruleset: fraud_detection_core  # All 6 rules are automatically available
```

The compiler resolves transitive dependencies automatically:
```
Pipeline imports: fraud_detection_core
  ‚Üì
fraud_detection_core imports:
  - fraud_farm.yaml
  - account_takeover.yaml
  - velocity_abuse.yaml
  - amount_outlier.yaml
  - suspicious_geography.yaml
  - new_user_fraud.yaml
  ‚Üì
All 6 rules are available
```

### 6.3 Ruleset Include (Execution)

After importing a ruleset via the `imports` section, you can execute it in your pipeline steps:

```yaml
steps:
  - include:
      ruleset: login_risk_rules
```

The `include` step:
- Executes all rules in the ruleset
- Evaluates the ruleset's decision logic
- Returns a **signal** (`approve`, `decline`, `review`, `hold`, `pass`)
- Makes results available in `results.<ruleset_id>.signal`

**Note:** Both rulesets and pipelines use the same 5 signal types. The ruleset signal indicates the intermediate decision recommendation, while the pipeline makes the final decision based on signals from all rulesets.

### 6.4 Pipeline Include (Execution)

You can also include sub-pipelines:

```yaml
steps:
  - include:
      pipeline: common_feature_flow
```

### 6.5 Complete Example with Imports

**Fraud Detection Pipeline:**

```yaml
version: "0.1"

# Declare dependencies
imports:
  rulesets:
    - library/rulesets/fraud_detection_core.yaml

---

pipeline:
  id: fraud_detection_pipeline
  name: Fraud Detection Pipeline
  description: Production-grade fraud detection for transaction events

  # Pipeline only executes for transaction events
  when:
    event.type: transaction

  steps:
    # Execute the fraud detection ruleset
    - include:
        ruleset: fraud_detection_core
```

This 24-line pipeline replaces what would have been a 337-line monolithic file!

**Payment Pipeline with Branching:**

```yaml
version: "0.1"

imports:
  rulesets:
    - library/rulesets/payment_standard.yaml
    - library/rulesets/payment_high_value.yaml

---

pipeline:
  id: payment_pipeline
  name: Payment Risk Pipeline
  description: Payment risk assessment with conditional routing

  when:
    event.type: payment

  steps:
    # Feature extraction
    - type: extract
      id: extract_features

    # Branch based on transaction amount
    - branch:
        when:
          # High-value transactions (> $1000)
          - condition: event.transaction.amount > 1000
            pipeline:
              - include:
                  ruleset: payment_high_value  # Stricter thresholds

          # Standard transactions
          - default: true
            pipeline:
              - include:
                  ruleset: payment_standard  # Normal thresholds
```

### 6.6 Import Path Resolution

Import paths are resolved relative to the repository root:

```
repository/
‚îú‚îÄ‚îÄ library/
‚îÇ   ‚îú‚îÄ‚îÄ rulesets/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fraud_detection_core.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ payment_high_value.yaml
‚îÇ   ‚îî‚îÄ‚îÄ pipelines/
‚îÇ       ‚îî‚îÄ‚îÄ common_feature_extraction.yaml
‚îî‚îÄ‚îÄ pipelines/
    ‚îî‚îÄ‚îÄ fraud_detection.yaml  ‚Üê You are here
```

From `fraud_detection.yaml`, you import using paths relative to repository root:
```yaml
imports:
  rulesets:
    - library/rulesets/fraud_detection_core.yaml  # ‚úÖ Correct
```

### 6.7 Multiple Rulesets in One Pipeline

You can import and use multiple rulesets in a single pipeline:

```yaml
version: "0.1"

imports:
  rulesets:
    - library/rulesets/device_risk.yaml
    - library/rulesets/geo_risk.yaml
    - library/rulesets/behavioral_risk.yaml

---

pipeline:
  id: comprehensive_risk_pipeline
  name: Comprehensive Risk Assessment

  steps:
    # Step 1: Device risk assessment
    - include:
        ruleset: device_risk

    # Step 2: Geographic risk assessment
    - include:
        ruleset: geo_risk

    # Step 3: Behavioral risk assessment
    - include:
        ruleset: behavioral_risk

    # Step 4: Aggregate all risk scores
    - aggregate:
        method: weighted
        weights:
          results.device_risk.total_score: 0.4
          results.geo_risk.total_score: 0.3
          results.behavioral_risk.total_score: 0.3
```

### 6.8 Conditional Ruleset Execution

You can conditionally execute rulesets based on pipeline state:

```yaml
steps:
  # Execute high-value ruleset only for large transactions
  - include:
      ruleset: payment_high_value
    if: event.transaction.amount > 10000

  # Execute standard ruleset for normal transactions
  - include:
      ruleset: payment_standard
    if: event.transaction.amount <= 10000
```

### 6.9 Benefits of Import-Based Pipelines

1. **Massive Code Reduction** - 80-90% reduction in pipeline file size
2. **Reusability** - Same rulesets used across multiple pipelines
3. **Maintainability** - Update rules in one place, all pipelines benefit
4. **Clarity** - Pipeline focus on orchestration, not rule details
5. **Testability** - Test rules and rulesets independently
6. **Type Safety** - Compiler validates all IDs at compile time

---

## 7. Decision Logic (‚úÖ Implemented)

Pipelines support optional `decision` blocks to map ruleset signals to final results. This enables pipelines to orchestrate decisions from multiple rulesets.

### 7.1 Two-Level Decision Architecture

CORINT uses a two-level decision architecture:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 2: Ruleset (Decision Suggestions)        ‚îÇ
‚îÇ - Evaluates rules                               ‚îÇ
‚îÇ - conclusion: produces signals                  ‚îÇ
‚îÇ - Signals: approve/decline/review/hold/pass     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ signals
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 3: Pipeline (Final Decision Maker)       ‚îÇ
‚îÇ - Maps signals to final results                ‚îÇ
‚îÇ - decision: produces final decision             ‚îÇ
‚îÇ - Results: approve/decline/review/hold          ‚îÇ
‚îÇ - Can add actions and routing                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Concepts:**
- **Rulesets** produce **signals** (suggestions) via `conclusion`
- **Pipelines** make **final decisions** via `decision` by mapping signals to results
- Rulesets are reusable across pipelines with different decision mappings

### 7.2 Decision Rule Structure

```yaml
decision:
  - when: <condition>          # When to apply this decision
    result: <result>           # Final result: approve/decline/review/hold
    actions: [...]             # Optional: actions to execute
    reason: <reason>           # Optional: reason for decision
    terminate: true            # Optional: stop evaluating further rules

  - default: true              # Default/catch-all rule
    result: approve
    reason: "No risk detected"
```

**Fields:**
| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `when` | WhenBlock | No (if default) | Condition to evaluate (e.g., `results.fraud_check.signal == "decline"`) |
| `default` | bool | No | If true, this is the catch-all rule (no `when` needed) |
| `result` | string | Yes | Final decision: `approve`, `decline`, `review`, `hold` |
| `actions` | array | No | Actions to execute (e.g., `["KYC", "2FA"]`) |
| `reason` | string | No | Human-readable reason (supports templates like `"{results.fraud_check.reason}"`) |
| `terminate` | bool | No | If true, stop evaluating further decision rules |

### 7.3 Complete Example

```yaml
pipeline:
  id: login_risk_pipeline
  name: Login Risk Pipeline
  entry: fraud_check

  when:
    all:
      - event.type == "login"

  steps:
    - step:
        id: fraud_check
        name: Fraud Detection
        type: ruleset
        ruleset: login_risk_assessment
        # Ruleset produces signal via conclusion

  # Pipeline decision maps signals to final results
  decision:
    # Decline signal ‚Üí decline result
    - when: results.login_risk_assessment.signal == "decline"
      result: decline
      reason: "{results.login_risk_assessment.reason}"
      terminate: true

    # Review signal ‚Üí review result with actions
    - when: results.login_risk_assessment.signal == "review"
      result: review
      actions: ["manual_review", "2FA"]
      reason: "{results.login_risk_assessment.reason}"
      terminate: true

    # Default: approve
    - default: true
      result: approve
      reason: "Login approved"
```

### 7.4 When to Use Pipeline Decision

**Use Pipeline `decision` when:**
- Orchestrating multiple rulesets with different signals
- Mapping ruleset signals to different final results
- Adding pipeline-specific actions or routing
- Overriding or transforming ruleset suggestions

**Use Ruleset `conclusion` when:**
- Single ruleset producing the final decision
- Decision logic is tightly coupled to the rules
- Want maximum reusability of rulesets

**Example - Multiple Rulesets:**

```yaml
pipeline:
  id: comprehensive_risk
  entry: step1

  steps:
    - step:
        id: step1
        type: ruleset
        ruleset: fraud_detection
        next: step2

    - step:
        id: step2
        type: ruleset
        ruleset: compliance_check

  # Combine signals from both rulesets
  decision:
    # If either signals decline, decline
    - when:
        any:
          - results.fraud_detection.signal == "decline"
          - results.compliance_check.signal == "decline"
      result: decline
      reason: "Failed risk or compliance check"
      terminate: true

    # If both approve, approve
    - when:
        all:
          - results.fraud_detection.signal == "approve"
          - results.compliance_check.signal == "approve"
      result: approve
      reason: "Passed all checks"
      terminate: true

    # Otherwise, review
    - default: true
      result: review
      actions: ["manual_review"]
      reason: "Mixed signals from risk engines"
```

---

## 8. Full Pipeline Example

### 8.1 Login Risk Processing Pipeline (‚úÖ Correct Syntax)

```yaml
version: "0.1"

pipeline:
  id: login_risk_pipeline
  name: Login Risk Assessment Pipeline
  description: Comprehensive login risk evaluation
  entry: ip_check

  # Only process login events
  when:
    all:
      - event.type == "login"

  steps:
    # Step 1: Check IP reputation
    - step:
        id: ip_check
        name: IP Reputation Check
        type: api
        api: ip_reputation_service
        endpoint: check_ip
        params:
          ip_address: event.ip_address
        next: login_risk_check

    # Step 2: Execute login risk ruleset
    - step:
        id: login_risk_check
        name: Login Risk Assessment
        type: ruleset
        ruleset: login_risk_rules
```

**Note:** The ruleset `login_risk_rules` would contain the `conclusion` block with decision logic (signals, actions, reasons). See [ruleset.md](ruleset.md) for details.

### 8.2 Legacy Format Example (With Unsupported Features)

```yaml
# THIS IS LEGACY/ASPIRATIONAL FORMAT - Some features not implemented
version: "0.2"

pipeline:
  id: legacy_example
  name: Legacy Format Example

  steps:
    # Legacy extract step (still supported)
    - type: extract
      id: extract_device

    # Parallel execution (legacy format only)
    - parallel:
        - device_fingerprint
        - ip_reputation
      merge:
        method: all

    # Include ruleset (legacy shorthand)
    - include:
        ruleset: login_risk_rules

    # Aggregation (NOT IMPLEMENTED)
    - aggregate:
        method: weighted
        weights:
          rules: 0.5
          ip: 0.5

  # Pipeline decision (NOT IMPLEMENTED)
  decision:
    - when: results.login_risk_rules.signal == "decline"
      result: decline
      actions: ["BLOCK_DEVICE"]
      reason: "High risk"
      terminate: true
```

---

### 8.3 Multi-Event Router Pipeline (‚úÖ Correct Syntax)

```yaml
version: "0.1"

pipeline:
  id: multi_event_router
  name: Multi-Event Type Router
  description: Routes different event types to appropriate processing pipelines
  entry: event_router

  steps:
    # Router step to direct to different flows
    - step:
        id: event_router
        name: Event Type Router
        type: router
        routes:
          - next: login_flow
            when:
              all:
                - event.type == "login"
          - next: payment_flow
            when:
              all:
                - event.type == "payment"
          - next: crypto_flow
            when:
              all:
                - event.type == "crypto_transfer"
        default: default_flow

    # Login processing
    - step:
        id: login_flow
        name: Login Risk Check
        type: ruleset
        ruleset: login_risk_rules

    # Payment processing
    - step:
        id: payment_flow
        name: Payment Risk Check
        type: ruleset
        ruleset: payment_risk_rules

    # Crypto processing
    - step:
        id: crypto_flow
        name: Crypto Risk Check
        type: ruleset
        ruleset: web3_wallet_risk

    # Default processing
    - step:
        id: default_flow
        name: Default Processing
        type: ruleset
        ruleset: default_rules
```

---

### 8.4 Service Integration Pipeline (‚úÖ Correct Syntax)

```yaml
version: "0.1"

pipeline:
  id: service_integration_pipeline
  name: Service Integration Example
  entry: load_user_profile

  steps:
    # Step 1: Load user profile from database
    - step:
        id: load_user_profile
        name: Load User Profile
        type: service
        service: user_db
        query: get_user_profile
        params:
          user_id: event.user.id
        output: context.user_profile
        next: check_risk_cache

    # Step 2: Check cache for existing risk score
    - step:
        id: check_risk_cache
        name: Check Risk Cache
        type: service
        service: redis_cache
        query: get_user_risk_cache
        output: context.cached_risk
        next: ip_reputation

    # Step 3: Check external API
    - step:
        id: ip_reputation
        name: IP Reputation Check
        type: api
        api: maxmind
        endpoint: ip_lookup
        params:
          ip: event.ip_address
        next: risk_assessment

    # Step 4: Execute rules with all context
    - step:
        id: risk_assessment
        name: Risk Assessment
        type: ruleset
        ruleset: comprehensive_risk_check
        next: publish_decision

    # Step 5: Publish decision to message queue
    - step:
        id: publish_decision
        name: Publish Decision
        type: trigger
        target: event_bus.risk_decisions
        params:
          decision: results.comprehensive_risk_check.signal
```

---

## 9. BNF Grammar (Formal)

```
PIPELINE ::=
      "pipeline:"
         "id:" STRING
         [ "name:" STRING ]
         [ "description:" STRING ]
         "entry:" STRING
         [ "when:" WHEN_BLOCK ]
         "steps:" STEP_LIST
         [ "metadata:" METADATA_MAP ]

WHEN_BLOCK ::=
      "all:" CONDITION_LIST
    | "any:" CONDITION_LIST

CONDITION_LIST ::= "-" EXPRESSION { "-" EXPRESSION }

STEP_LIST ::= "-" STEP { "-" STEP }

STEP ::= "step:" STEP_BODY

STEP_BODY ::=
      "id:" STRING
      [ "name:" STRING ]
      "type:" STEP_TYPE
      [ "when:" WHEN_BLOCK ]
      [ STEP_TYPE_PARAMS ]
      [ "next:" STRING ]

STEP_TYPE ::= "ruleset" | "router" | "api" | "llm" | "action" | "custom"

STEP_TYPE_PARAMS ::=
      RULESET_PARAMS
    | ROUTER_PARAMS
    | API_PARAMS
    | LLM_PARAMS

RULESET_PARAMS ::= "ruleset:" STRING

ROUTER_PARAMS ::=
      "routes:" ROUTE_LIST
      [ "default:" STRING ]

ROUTE_LIST ::= "-" ROUTE { "-" ROUTE }

ROUTE ::=
      "next:" STRING
      "when:" WHEN_BLOCK

API_PARAMS ::=
      "api:" STRING
      [ "params:" OBJECT ]

LLM_PARAMS ::=
      "llm:" STRING
      [ "params:" OBJECT ]

METADATA_MAP ::= KEY ":" VALUE { KEY ":" VALUE }

OBJECT ::= KEY ":" VALUE { KEY ":" VALUE }
```

---

## 10. Related Documentation

For comprehensive understanding of pipelines and the CORINT ecosystem:

### Core Concepts
- **[imports.md](imports.md)** - Complete module system and dependency management specification
- **[ruleset.md](ruleset.md)** - Ruleset specification and decision logic
- **[rule.md](rule.md)** - Individual rule specification

### Advanced Topics
- **[expression.md](expression.md)** - Expression language for conditions
- **[context.md](context.md)** - Context management and data flow between steps
- **[feature.md](feature.md)** - Feature engineering and extraction

### Integration
- **[service.md](service.md)** - Internal service integration (databases, caches, microservices)
- **[external.md](external.md)** - External API integration
- **[llm.md](llm.md)** - LLM integration for cognitive reasoning

### Architecture
- **[overall.md](overall.md)** - High-level RDL overview
- **[ARCHITECTURE.md](../ARCHITECTURE.md)** - Three-layer decision architecture

---

## 11. Summary

### 11.1 What's Implemented (‚úÖ)

A CORINT Pipeline currently supports:

**Core Structure:**
- ‚úÖ `id`, `name`, `description` - Basic metadata
- ‚úÖ `entry` - Explicit DAG entry point (required)
- ‚úÖ `when` - Conditional pipeline execution
- ‚úÖ `steps` - Processing step orchestration
- ‚úÖ `metadata` - Arbitrary key-value metadata

**Step Types:**
- ‚úÖ `router` - Conditional routing with routes
- ‚úÖ `function` - Pure computation
- ‚úÖ `rule` - Single rule execution
- ‚úÖ `ruleset` - Ruleset execution (produces signals)
- ‚úÖ `pipeline` - Sub-pipeline calls
- ‚úÖ `service` - Internal service calls
- ‚úÖ `api` - External API calls (single, any, all modes)
- ‚úÖ `trigger` - External actions
- ‚úÖ `extract`, `reason` - Legacy format support

**Features:**
- ‚úÖ Imports system for modular composition
- ‚úÖ Automatic transitive dependency resolution
- ‚úÖ Compile-time validation
- ‚úÖ Router steps for conditional flows
- ‚úÖ Sequential execution with explicit `next`

### 11.2 What's Planned (üìã)

**Not Yet Implemented:**
- üìã Pipeline-level `decision` blocks (use Ruleset `conclusion` instead)
- üìã Parallel execution in new format (legacy format only)
- üìã Branching in new format (use `router` step instead)
- üìã Aggregation steps (use expression features instead)
- üìã `score` and `action` step types

### 11.3 Current Architecture

**Decision-Making Model:**
- **Rules** (‚úÖ) - Detect and score individual risk patterns
- **Rulesets** (‚úÖ) - Produce **signals** via `conclusion` blocks
  - Signals: `approve`, `decline`, `review`, `hold`, `pass`
  - Actions: `KYC`, `OTP`, `2FA`, `BLOCK_DEVICE`, etc.
- **Pipelines** (‚úÖ) - Orchestrate execution, route events
  - Currently: NO decision logic at pipeline level
  - Decision logic resides in Rulesets

**Why This Works:**
- Rulesets already provide all needed decision capabilities
- Simpler architecture with single decision point
- Same ruleset can be reused across multiple pipelines
- Clear separation: Pipelines orchestrate, Rulesets decide

### 11.4 Benefits

- ‚úÖ 80-90% code reduction through modular design
- ‚úÖ Dependencies resolved at compile time
- ‚úÖ Type-safe ID references
- ‚úÖ Reusable rulesets across pipelines
- ‚úÖ Clear separation of concerns

It is the highest-level construct of CORINT's Risk Definition Language (RDL).
